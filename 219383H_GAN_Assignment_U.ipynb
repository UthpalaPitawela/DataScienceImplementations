{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "219383H_GAN-Assignment-U.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "61a80c6561fa47c298c8b7a041cf7492": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6324d7a5a1914b5f92ba1d4b3e93b565",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f74dc06cec984f71a999c5a51ab9b624",
              "IPY_MODEL_8f4ae5f72b0a409e943461fe1241709a"
            ]
          }
        },
        "6324d7a5a1914b5f92ba1d4b3e93b565": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f74dc06cec984f71a999c5a51ab9b624": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_69d1c6f475084858a8a20c82eebe08d4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 9912422,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 9912422,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d1363cdb0f0c4e3f97048581f01b329f"
          }
        },
        "8f4ae5f72b0a409e943461fe1241709a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_19acff6f8d88472089c21c585db5a74b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 9913344/? [25:19&lt;00:00, 6525.67it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_62136df947184b2791be52ffecdcf5b4"
          }
        },
        "69d1c6f475084858a8a20c82eebe08d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d1363cdb0f0c4e3f97048581f01b329f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "19acff6f8d88472089c21c585db5a74b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "62136df947184b2791be52ffecdcf5b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "53c6a51dbef74b1facabddac594ba2cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_574b00b2759f4aecbf37f2a5d5cc0951",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e584fcd8b4ed4dafa0483a4da788d5b5",
              "IPY_MODEL_2444bb3e34c241c8bd7810db1a3234f9"
            ]
          }
        },
        "574b00b2759f4aecbf37f2a5d5cc0951": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e584fcd8b4ed4dafa0483a4da788d5b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e2466448447445d3a1f969b6ce53670d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28881,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28881,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2d41deeb01eb4f9fa8a8df9ebfdbb981"
          }
        },
        "2444bb3e34c241c8bd7810db1a3234f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_22aaa828880944b0838ec3fc90dc24fd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 29696/? [00:40&lt;00:00, 742.37it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fdd1b7434068440c9d3e776520700753"
          }
        },
        "e2466448447445d3a1f969b6ce53670d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2d41deeb01eb4f9fa8a8df9ebfdbb981": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "22aaa828880944b0838ec3fc90dc24fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fdd1b7434068440c9d3e776520700753": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5db899f607a54d9fa8434f25ba970cf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_37cc571b657b4e6e98022be4059279c6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ed7f8d298ad643cc800a6f96f1ab2255",
              "IPY_MODEL_4ccd0d90bcbb4839ac28dc892c3eadc8"
            ]
          }
        },
        "37cc571b657b4e6e98022be4059279c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ed7f8d298ad643cc800a6f96f1ab2255": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4632231af91c42db93285b87deb576a0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1648877,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1648877,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_21b36d6521634e7c9a4b117786d19491"
          }
        },
        "4ccd0d90bcbb4839ac28dc892c3eadc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9d91bac6e0c248638b589351b0efa445",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1649664/? [00:39&lt;00:00, 41829.63it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1b49e77ae9eb469fbf373fbebcd24a88"
          }
        },
        "4632231af91c42db93285b87deb576a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "21b36d6521634e7c9a4b117786d19491": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9d91bac6e0c248638b589351b0efa445": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1b49e77ae9eb469fbf373fbebcd24a88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3fee59f3c33d423a94174165c7696ab9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_214a5bff4f09499fa217ee2983acdf50",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1a68ecc01c5849598663143fb88ccd49",
              "IPY_MODEL_bcc4583b87b14ab6b979cf7b04f373c0"
            ]
          }
        },
        "214a5bff4f09499fa217ee2983acdf50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1a68ecc01c5849598663143fb88ccd49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_713f800e3a53438b97c8239aebcae30b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 4542,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4542,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3884848084f74d6da137455d461a6130"
          }
        },
        "bcc4583b87b14ab6b979cf7b04f373c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fb2095abc0704cf1b1ad72810617d51f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5120/? [20:28&lt;00:00,  4.17it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d362e29f51434ef3b98136fc2c1cef6c"
          }
        },
        "713f800e3a53438b97c8239aebcae30b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3884848084f74d6da137455d461a6130": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fb2095abc0704cf1b1ad72810617d51f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d362e29f51434ef3b98136fc2c1cef6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UthpalaPitawela/Data_Science_Implementations/blob/main/219383H_GAN_Assignment_U.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WJ-pykBpiLi"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "from torchvision.utils import save_image\n",
        "import pickle as pkl\n",
        "from google.colab import files\n",
        "\n",
        "device = torch.device('cuda' \n",
        "                      if torch.cuda.is_available() \n",
        "                      else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "do_ACP_2jvca"
      },
      "source": [
        "**Create folders to save real and fake images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jKbLSSnj2nM"
      },
      "source": [
        "!mkdir s0\n",
        "!mkdir s1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zp7IJjRp_zmI"
      },
      "source": [
        "**Load MNIST dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534,
          "referenced_widgets": [
            "61a80c6561fa47c298c8b7a041cf7492",
            "6324d7a5a1914b5f92ba1d4b3e93b565",
            "f74dc06cec984f71a999c5a51ab9b624",
            "8f4ae5f72b0a409e943461fe1241709a",
            "69d1c6f475084858a8a20c82eebe08d4",
            "d1363cdb0f0c4e3f97048581f01b329f",
            "19acff6f8d88472089c21c585db5a74b",
            "62136df947184b2791be52ffecdcf5b4",
            "53c6a51dbef74b1facabddac594ba2cb",
            "574b00b2759f4aecbf37f2a5d5cc0951",
            "e584fcd8b4ed4dafa0483a4da788d5b5",
            "2444bb3e34c241c8bd7810db1a3234f9",
            "e2466448447445d3a1f969b6ce53670d",
            "2d41deeb01eb4f9fa8a8df9ebfdbb981",
            "22aaa828880944b0838ec3fc90dc24fd",
            "fdd1b7434068440c9d3e776520700753",
            "5db899f607a54d9fa8434f25ba970cf5",
            "37cc571b657b4e6e98022be4059279c6",
            "ed7f8d298ad643cc800a6f96f1ab2255",
            "4ccd0d90bcbb4839ac28dc892c3eadc8",
            "4632231af91c42db93285b87deb576a0",
            "21b36d6521634e7c9a4b117786d19491",
            "9d91bac6e0c248638b589351b0efa445",
            "1b49e77ae9eb469fbf373fbebcd24a88",
            "3fee59f3c33d423a94174165c7696ab9",
            "214a5bff4f09499fa217ee2983acdf50",
            "1a68ecc01c5849598663143fb88ccd49",
            "bcc4583b87b14ab6b979cf7b04f373c0",
            "713f800e3a53438b97c8239aebcae30b",
            "3884848084f74d6da137455d461a6130",
            "fb2095abc0704cf1b1ad72810617d51f",
            "d362e29f51434ef3b98136fc2c1cef6c"
          ]
        },
        "id": "WHzfPJrB70VM",
        "outputId": "cb75932f-6658-42d5-fc5f-8b98b2e56752"
      },
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "  transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "#Get train and test datasets\n",
        "train_dataset = datasets.MNIST(\n",
        "    root='data/',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform\n",
        "    )  \n",
        "\n",
        "test_dataset = datasets.MNIST(\n",
        "    root='data/', \n",
        "    train=False, \n",
        "    transform=transform\n",
        "    )\n",
        "\n",
        "#Used a data loader to iterarate train and test datasets\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset, \n",
        "    100,\n",
        "    shuffle=True\n",
        "    )\n",
        "\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_dataset, \n",
        "    100,\n",
        "    shuffle=True\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "61a80c6561fa47c298c8b7a041cf7492",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=9912422.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "53c6a51dbef74b1facabddac594ba2cb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=28881.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5db899f607a54d9fa8434f25ba970cf5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1648877.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3fee59f3c33d423a94174165c7696ab9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=4542.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6BIa5gx7DbM"
      },
      "source": [
        "**Define Generator class**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHtnuKw1dRoF"
      },
      "source": [
        "\n",
        "class Generator(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, g_output_size):\n",
        "        super(Generator, self).__init__()\n",
        "        \n",
        "        # define hidden linear layers\n",
        "        self.fc1 = nn.Linear(input_size, 256)\n",
        "        self.fc2 = nn.Linear(256, 512)\n",
        "        \n",
        "        # final fully-connected layer\n",
        "        self.fc3 = nn.Linear(512, g_output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Used leaky_relu as the activation function as it is a fix for the \"Dying Relu\" Problem \n",
        "        x = F.leaky_relu(self.fc1(x), 0.2) \n",
        "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
        "        out = torch.tanh(self.fc3(x)) # tanh is used as the activation function for the output layer\n",
        "\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJqW1saA609z"
      },
      "source": [
        "**Define Discrimator class**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEl7U-Qrzrc8"
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, d_output_size):\n",
        "        super(Discriminator, self).__init__()\n",
        "        \n",
        "        # define hidden linear layers\n",
        "        self.fc1 = nn.Linear(input_size, 1024)\n",
        "        self.fc2 = nn.Linear(1024, 512)\n",
        "        self.fc3 = nn.Linear(512, 256)\n",
        "        self.fc4 = nn.Linear(256, 128)\n",
        "        \n",
        "        # final fully-connected layer\n",
        "        self.fc5 = nn.Linear(128, d_output_size)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # flatten image: change to a 28x28 tensor\n",
        "        x = x.view(-1, 28*28) \n",
        "        # all hidden layers: Activation function is leaky_relu\n",
        "        x = F.leaky_relu(self.fc1(x), 0.2) \n",
        "        x = F.dropout(x, 0.3) #0.3 dropout used to reduce overfitting\n",
        "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
        "        x = F.dropout(x, 0.3)\n",
        "        x = F.leaky_relu(self.fc3(x), 0.2)\n",
        "        x = F.dropout(x, 0.3)\n",
        "        x = F.leaky_relu(self.fc4(x), 0.2)\n",
        "        x = F.dropout(x, 0.3)\n",
        "        # final layer: sigmoid used as the activation function for the output layer\n",
        "        out = torch.sigmoid(self.fc5(x))\n",
        "\n",
        "\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5mvgZU-9o9M"
      },
      "source": [
        "**Define hyper parameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpCg5qV_2Yei",
        "outputId": "cf90569f-505b-49e7-cb2d-fdd56f994ddf"
      },
      "source": [
        "\n",
        "# Discriminator hyperparameters\n",
        "\n",
        "# Size of input image to discriminator \n",
        "discriminator_input_size = 784\n",
        "\n",
        "# Size of discriminator output\n",
        "discrimiator_output_size = 1\n",
        "\n",
        "# Generator hyperparameters\n",
        "\n",
        "# Size of latent vector to give to generator\n",
        "z_size = 100\n",
        "# Size of discriminator output 28x28 (generated image)\n",
        "generator_output_size = 784\n",
        "\n",
        "\n",
        "D = Discriminator(discriminator_input_size, discrimiator_output_size).to(device)\n",
        "G = Generator(z_size, generator_output_size).to(device)\n",
        "\n",
        "print(\"Discriminator\", D)\n",
        "print (\"Generator\", G)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Discriminator Discriminator(\n",
            "  (fc1): Linear(in_features=784, out_features=1024, bias=True)\n",
            "  (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
            "  (fc3): Linear(in_features=512, out_features=256, bias=True)\n",
            "  (fc4): Linear(in_features=256, out_features=128, bias=True)\n",
            "  (fc5): Linear(in_features=128, out_features=1, bias=True)\n",
            ")\n",
            "Generator Generator(\n",
            "  (fc1): Linear(in_features=100, out_features=256, bias=True)\n",
            "  (fc2): Linear(in_features=256, out_features=512, bias=True)\n",
            "  (fc3): Linear(in_features=512, out_features=784, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AskYo9UPxbES"
      },
      "source": [
        "# BCELoss is a Softmax activation plus a Cross-Entropy loss\n",
        "criterion = nn.BCELoss() \n",
        "\n",
        "# optimizer optim.Adam is used; has some benefits;Computationally efficient, Little memory requirements.\n",
        "learning_rate = 0.0002 \n",
        "G_optimizer = optim.Adam(G.parameters(), lr = learning_rate)\n",
        "D_optimizer = optim.Adam(D.parameters(), lr = learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxEmNhZfvZ9K"
      },
      "source": [
        "**Train the discriminator**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmiP9uHaxedV"
      },
      "source": [
        "def D_train(x):\n",
        "    D.zero_grad()\n",
        "\n",
        "    # train discriminator with real images \n",
        "    x_real, y_real = x.view(-1, 28*28), torch.ones(100, 1)\n",
        "    x_real, y_real = Variable(x_real.to(device)), Variable(y_real.to(device))\n",
        "\n",
        "    D_output = D(x_real)\n",
        "    D_real_loss = criterion(D_output, y_real)\n",
        "    D_real_score = D_output\n",
        "\n",
        "    # train discriminator with fake images\n",
        "    z = Variable(torch.randn(100, 100).to(device))\n",
        "    x_fake, y_fake = G(z), Variable(torch.zeros(100, 1).to(device))\n",
        "\n",
        "    D_output = D(x_fake)\n",
        "    D_fake_loss = criterion(D_output, y_fake)\n",
        "    D_fake_score = D_output\n",
        "\n",
        "    # gradient backprop & optimize ONLY D's parameters\n",
        "    D_loss = D_real_loss + D_fake_loss\n",
        "    D_loss.backward()\n",
        "    D_optimizer.step()\n",
        "        \n",
        "    return  D_loss.data.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqZUfYbLvgfv"
      },
      "source": [
        "**Train the generator**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOGWeJVIFEDZ"
      },
      "source": [
        "def G_train(x):\n",
        "    G.zero_grad()\n",
        "\n",
        "    z = Variable(torch.randn(100, 100).to(device))\n",
        "    y = Variable(torch.ones(100, 1).to(device))\n",
        "\n",
        "    G_output = G(z)\n",
        "    D_output = D(G_output)\n",
        "    G_loss = criterion(D_output, y)\n",
        "\n",
        "    # gradient backprop & optimize ONLY Generator's parameters\n",
        "    G_loss.backward()\n",
        "    G_optimizer.step()\n",
        "        \n",
        "    return G_loss.data.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hONjC0ixnxa",
        "outputId": "7629d375-5b16-4b4b-cc17-b5403284da6f"
      },
      "source": [
        "n_epoch = 200\n",
        "for epoch in range(1, n_epoch+1):           \n",
        "    D_losses, G_losses = [], []\n",
        "    for batch_idx, (x, _) in enumerate(train_loader):\n",
        "        D_losses.append(D_train(x))\n",
        "        G_losses.append(G_train(x))\n",
        "\n",
        "    print('[%d/%d]: loss_d: %.3f, loss_g: %.3f' % (\n",
        "            (epoch), n_epoch, torch.mean(torch.FloatTensor(D_losses)), torch.mean(torch.FloatTensor(G_losses))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1/200]: loss_d: 0.370, loss_g: 3.546\n",
            "[2/200]: loss_d: 0.402, loss_g: 3.164\n",
            "[3/200]: loss_d: 0.427, loss_g: 3.142\n",
            "[4/200]: loss_d: 0.473, loss_g: 3.005\n",
            "[5/200]: loss_d: 0.500, loss_g: 2.893\n",
            "[6/200]: loss_d: 0.518, loss_g: 2.672\n",
            "[7/200]: loss_d: 0.508, loss_g: 2.782\n",
            "[8/200]: loss_d: 0.609, loss_g: 2.372\n",
            "[9/200]: loss_d: 0.640, loss_g: 2.332\n",
            "[10/200]: loss_d: 0.612, loss_g: 2.459\n",
            "[11/200]: loss_d: 0.651, loss_g: 2.259\n",
            "[12/200]: loss_d: 0.692, loss_g: 2.188\n",
            "[13/200]: loss_d: 0.704, loss_g: 2.134\n",
            "[14/200]: loss_d: 0.733, loss_g: 2.000\n",
            "[15/200]: loss_d: 0.743, loss_g: 2.004\n",
            "[16/200]: loss_d: 0.710, loss_g: 2.078\n",
            "[17/200]: loss_d: 0.756, loss_g: 2.047\n",
            "[18/200]: loss_d: 0.763, loss_g: 1.932\n",
            "[19/200]: loss_d: 0.754, loss_g: 1.970\n",
            "[20/200]: loss_d: 0.748, loss_g: 2.006\n",
            "[21/200]: loss_d: 0.772, loss_g: 1.913\n",
            "[22/200]: loss_d: 0.767, loss_g: 1.946\n",
            "[23/200]: loss_d: 0.768, loss_g: 1.933\n",
            "[24/200]: loss_d: 0.799, loss_g: 1.885\n",
            "[25/200]: loss_d: 0.799, loss_g: 1.887\n",
            "[26/200]: loss_d: 0.807, loss_g: 1.880\n",
            "[27/200]: loss_d: 0.813, loss_g: 1.819\n",
            "[28/200]: loss_d: 0.830, loss_g: 1.745\n",
            "[29/200]: loss_d: 0.854, loss_g: 1.727\n",
            "[30/200]: loss_d: 0.857, loss_g: 1.756\n",
            "[31/200]: loss_d: 0.858, loss_g: 1.739\n",
            "[32/200]: loss_d: 0.860, loss_g: 1.728\n",
            "[33/200]: loss_d: 0.864, loss_g: 1.718\n",
            "[34/200]: loss_d: 0.866, loss_g: 1.698\n",
            "[35/200]: loss_d: 0.873, loss_g: 1.670\n",
            "[36/200]: loss_d: 0.909, loss_g: 1.611\n",
            "[37/200]: loss_d: 0.906, loss_g: 1.626\n",
            "[38/200]: loss_d: 0.895, loss_g: 1.638\n",
            "[39/200]: loss_d: 0.897, loss_g: 1.609\n",
            "[40/200]: loss_d: 0.916, loss_g: 1.589\n",
            "[41/200]: loss_d: 0.911, loss_g: 1.587\n",
            "[42/200]: loss_d: 0.921, loss_g: 1.569\n",
            "[43/200]: loss_d: 0.932, loss_g: 1.548\n",
            "[44/200]: loss_d: 0.936, loss_g: 1.538\n",
            "[45/200]: loss_d: 0.940, loss_g: 1.545\n",
            "[46/200]: loss_d: 0.931, loss_g: 1.547\n",
            "[47/200]: loss_d: 0.940, loss_g: 1.508\n",
            "[48/200]: loss_d: 0.941, loss_g: 1.566\n",
            "[49/200]: loss_d: 0.950, loss_g: 1.524\n",
            "[50/200]: loss_d: 0.943, loss_g: 1.521\n",
            "[51/200]: loss_d: 0.953, loss_g: 1.511\n",
            "[52/200]: loss_d: 0.955, loss_g: 1.492\n",
            "[53/200]: loss_d: 0.967, loss_g: 1.490\n",
            "[54/200]: loss_d: 0.947, loss_g: 1.510\n",
            "[55/200]: loss_d: 0.967, loss_g: 1.479\n",
            "[56/200]: loss_d: 0.962, loss_g: 1.497\n",
            "[57/200]: loss_d: 0.963, loss_g: 1.489\n",
            "[58/200]: loss_d: 0.962, loss_g: 1.487\n",
            "[59/200]: loss_d: 0.969, loss_g: 1.458\n",
            "[60/200]: loss_d: 0.965, loss_g: 1.480\n",
            "[61/200]: loss_d: 0.975, loss_g: 1.474\n",
            "[62/200]: loss_d: 0.968, loss_g: 1.455\n",
            "[63/200]: loss_d: 0.973, loss_g: 1.445\n",
            "[64/200]: loss_d: 0.974, loss_g: 1.457\n",
            "[65/200]: loss_d: 0.971, loss_g: 1.475\n",
            "[66/200]: loss_d: 0.975, loss_g: 1.459\n",
            "[67/200]: loss_d: 0.982, loss_g: 1.432\n",
            "[68/200]: loss_d: 0.974, loss_g: 1.437\n",
            "[69/200]: loss_d: 0.975, loss_g: 1.450\n",
            "[70/200]: loss_d: 0.973, loss_g: 1.459\n",
            "[71/200]: loss_d: 0.987, loss_g: 1.424\n",
            "[72/200]: loss_d: 0.981, loss_g: 1.439\n",
            "[73/200]: loss_d: 0.982, loss_g: 1.422\n",
            "[74/200]: loss_d: 0.983, loss_g: 1.431\n",
            "[75/200]: loss_d: 0.985, loss_g: 1.431\n",
            "[76/200]: loss_d: 0.984, loss_g: 1.431\n",
            "[77/200]: loss_d: 0.985, loss_g: 1.430\n",
            "[78/200]: loss_d: 0.990, loss_g: 1.415\n",
            "[79/200]: loss_d: 0.996, loss_g: 1.401\n",
            "[80/200]: loss_d: 0.993, loss_g: 1.410\n",
            "[81/200]: loss_d: 0.991, loss_g: 1.428\n",
            "[82/200]: loss_d: 0.990, loss_g: 1.411\n",
            "[83/200]: loss_d: 0.992, loss_g: 1.410\n",
            "[84/200]: loss_d: 0.994, loss_g: 1.401\n",
            "[85/200]: loss_d: 1.000, loss_g: 1.404\n",
            "[86/200]: loss_d: 0.993, loss_g: 1.404\n",
            "[87/200]: loss_d: 1.000, loss_g: 1.394\n",
            "[88/200]: loss_d: 1.002, loss_g: 1.379\n",
            "[89/200]: loss_d: 1.001, loss_g: 1.391\n",
            "[90/200]: loss_d: 0.997, loss_g: 1.385\n",
            "[91/200]: loss_d: 1.001, loss_g: 1.392\n",
            "[92/200]: loss_d: 0.999, loss_g: 1.391\n",
            "[93/200]: loss_d: 1.004, loss_g: 1.378\n",
            "[94/200]: loss_d: 1.007, loss_g: 1.389\n",
            "[95/200]: loss_d: 1.004, loss_g: 1.387\n",
            "[96/200]: loss_d: 1.010, loss_g: 1.378\n",
            "[97/200]: loss_d: 1.006, loss_g: 1.378\n",
            "[98/200]: loss_d: 1.009, loss_g: 1.379\n",
            "[99/200]: loss_d: 1.012, loss_g: 1.361\n",
            "[100/200]: loss_d: 1.006, loss_g: 1.390\n",
            "[101/200]: loss_d: 1.016, loss_g: 1.370\n",
            "[102/200]: loss_d: 1.012, loss_g: 1.363\n",
            "[103/200]: loss_d: 1.014, loss_g: 1.366\n",
            "[104/200]: loss_d: 1.016, loss_g: 1.376\n",
            "[105/200]: loss_d: 1.016, loss_g: 1.374\n",
            "[106/200]: loss_d: 1.009, loss_g: 1.368\n",
            "[107/200]: loss_d: 1.018, loss_g: 1.353\n",
            "[108/200]: loss_d: 1.009, loss_g: 1.380\n",
            "[109/200]: loss_d: 1.015, loss_g: 1.370\n",
            "[110/200]: loss_d: 1.017, loss_g: 1.356\n",
            "[111/200]: loss_d: 1.019, loss_g: 1.348\n",
            "[112/200]: loss_d: 1.018, loss_g: 1.363\n",
            "[113/200]: loss_d: 1.020, loss_g: 1.376\n",
            "[114/200]: loss_d: 1.015, loss_g: 1.369\n",
            "[115/200]: loss_d: 1.018, loss_g: 1.355\n",
            "[116/200]: loss_d: 1.023, loss_g: 1.333\n",
            "[117/200]: loss_d: 1.020, loss_g: 1.353\n",
            "[118/200]: loss_d: 1.024, loss_g: 1.347\n",
            "[119/200]: loss_d: 1.025, loss_g: 1.352\n",
            "[120/200]: loss_d: 1.019, loss_g: 1.365\n",
            "[121/200]: loss_d: 1.016, loss_g: 1.372\n",
            "[122/200]: loss_d: 1.019, loss_g: 1.356\n",
            "[123/200]: loss_d: 1.013, loss_g: 1.370\n",
            "[124/200]: loss_d: 1.017, loss_g: 1.357\n",
            "[125/200]: loss_d: 1.017, loss_g: 1.361\n",
            "[126/200]: loss_d: 1.018, loss_g: 1.362\n",
            "[127/200]: loss_d: 1.019, loss_g: 1.362\n",
            "[128/200]: loss_d: 1.022, loss_g: 1.343\n",
            "[129/200]: loss_d: 1.026, loss_g: 1.333\n",
            "[130/200]: loss_d: 1.022, loss_g: 1.350\n",
            "[131/200]: loss_d: 1.022, loss_g: 1.341\n",
            "[132/200]: loss_d: 1.021, loss_g: 1.357\n",
            "[133/200]: loss_d: 1.025, loss_g: 1.343\n",
            "[134/200]: loss_d: 1.022, loss_g: 1.345\n",
            "[135/200]: loss_d: 1.025, loss_g: 1.349\n",
            "[136/200]: loss_d: 1.020, loss_g: 1.351\n",
            "[137/200]: loss_d: 1.026, loss_g: 1.341\n",
            "[138/200]: loss_d: 1.028, loss_g: 1.337\n",
            "[139/200]: loss_d: 1.025, loss_g: 1.338\n",
            "[140/200]: loss_d: 1.017, loss_g: 1.366\n",
            "[141/200]: loss_d: 1.021, loss_g: 1.342\n",
            "[142/200]: loss_d: 1.025, loss_g: 1.348\n",
            "[143/200]: loss_d: 1.017, loss_g: 1.371\n",
            "[144/200]: loss_d: 1.023, loss_g: 1.358\n",
            "[145/200]: loss_d: 1.021, loss_g: 1.349\n",
            "[146/200]: loss_d: 1.029, loss_g: 1.341\n",
            "[147/200]: loss_d: 1.021, loss_g: 1.349\n",
            "[148/200]: loss_d: 1.019, loss_g: 1.374\n",
            "[149/200]: loss_d: 1.016, loss_g: 1.377\n",
            "[150/200]: loss_d: 1.025, loss_g: 1.342\n",
            "[151/200]: loss_d: 1.026, loss_g: 1.364\n",
            "[152/200]: loss_d: 1.024, loss_g: 1.333\n",
            "[153/200]: loss_d: 1.027, loss_g: 1.347\n",
            "[154/200]: loss_d: 1.020, loss_g: 1.361\n",
            "[155/200]: loss_d: 1.025, loss_g: 1.358\n",
            "[156/200]: loss_d: 1.024, loss_g: 1.339\n",
            "[157/200]: loss_d: 1.028, loss_g: 1.340\n",
            "[158/200]: loss_d: 1.027, loss_g: 1.345\n",
            "[159/200]: loss_d: 1.027, loss_g: 1.351\n",
            "[160/200]: loss_d: 1.023, loss_g: 1.351\n",
            "[161/200]: loss_d: 1.025, loss_g: 1.354\n",
            "[162/200]: loss_d: 1.027, loss_g: 1.332\n",
            "[163/200]: loss_d: 1.030, loss_g: 1.344\n",
            "[164/200]: loss_d: 1.023, loss_g: 1.359\n",
            "[165/200]: loss_d: 1.022, loss_g: 1.350\n",
            "[166/200]: loss_d: 1.020, loss_g: 1.361\n",
            "[167/200]: loss_d: 1.024, loss_g: 1.361\n",
            "[168/200]: loss_d: 1.028, loss_g: 1.333\n",
            "[169/200]: loss_d: 1.028, loss_g: 1.350\n",
            "[170/200]: loss_d: 1.024, loss_g: 1.346\n",
            "[171/200]: loss_d: 1.025, loss_g: 1.340\n",
            "[172/200]: loss_d: 1.027, loss_g: 1.339\n",
            "[173/200]: loss_d: 1.024, loss_g: 1.359\n",
            "[174/200]: loss_d: 1.030, loss_g: 1.339\n",
            "[175/200]: loss_d: 1.022, loss_g: 1.346\n",
            "[176/200]: loss_d: 1.026, loss_g: 1.348\n",
            "[177/200]: loss_d: 1.029, loss_g: 1.350\n",
            "[178/200]: loss_d: 1.031, loss_g: 1.328\n",
            "[179/200]: loss_d: 1.030, loss_g: 1.336\n",
            "[180/200]: loss_d: 1.031, loss_g: 1.345\n",
            "[181/200]: loss_d: 1.028, loss_g: 1.358\n",
            "[182/200]: loss_d: 1.028, loss_g: 1.339\n",
            "[183/200]: loss_d: 1.029, loss_g: 1.343\n",
            "[184/200]: loss_d: 1.028, loss_g: 1.347\n",
            "[185/200]: loss_d: 1.024, loss_g: 1.361\n",
            "[186/200]: loss_d: 1.026, loss_g: 1.348\n",
            "[187/200]: loss_d: 1.032, loss_g: 1.329\n",
            "[188/200]: loss_d: 1.028, loss_g: 1.352\n",
            "[189/200]: loss_d: 1.024, loss_g: 1.347\n",
            "[190/200]: loss_d: 1.024, loss_g: 1.346\n",
            "[191/200]: loss_d: 1.026, loss_g: 1.352\n",
            "[192/200]: loss_d: 1.023, loss_g: 1.351\n",
            "[193/200]: loss_d: 1.032, loss_g: 1.332\n",
            "[194/200]: loss_d: 1.030, loss_g: 1.342\n",
            "[195/200]: loss_d: 1.023, loss_g: 1.365\n",
            "[196/200]: loss_d: 1.026, loss_g: 1.335\n",
            "[197/200]: loss_d: 1.026, loss_g: 1.348\n",
            "[198/200]: loss_d: 1.027, loss_g: 1.345\n",
            "[199/200]: loss_d: 1.026, loss_g: 1.359\n",
            "[200/200]: loss_d: 1.025, loss_g: 1.349\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lueFSKX9vxlb"
      },
      "source": [
        "**Download the discriminator and generator**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7Rr69h_DmLa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "072061e6-7662-4284-fc18-ebc3e12a83b9"
      },
      "source": [
        "# Save the Generator\n",
        "with open('G.pkl', 'wb') as f:\n",
        "    pkl.dump(G, f)\n",
        "\n",
        "# Save the Discriminator\n",
        "with open('D.pkl', 'wb') as f:\n",
        "    pkl.dump(D, f)\n",
        "\n",
        "\n",
        "# download files into the local machine\n",
        "files.download('D.pkl')\n",
        "files.download('G.pkl')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_61acca5a-6e0e-4284-88f5-d418f9f3d495\", \"D.pkl\", 5976316)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_7c32d768-48ae-43e6-934c-364c5a495a74\", \"G.pkl\", 2241365)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4roumeKGwCN7"
      },
      "source": [
        "**Create the fake/s1 image set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfBOrx-XB6m7"
      },
      "source": [
        "\n",
        "from torchvision.utils import save_image\n",
        "import numpy as np\n",
        "\n",
        "sample_size=200\n",
        "#create 100 latent vectors which has 100  dimension\n",
        "z = np.random.uniform(-1, 1, size=(sample_size, z_size))\n",
        "z = torch.from_numpy(z).float()\n",
        "\n",
        "print(z[0].size())\n",
        "\n",
        "G.eval() # eval mode\n",
        "\n",
        "\n",
        "#get the grid image\n",
        "grid_view = G(z.to(device))\n",
        "save_image(grid_view.view(grid_view.size(0), 1, 28, 28), '/content/grid.png', normalize = True) \n",
        "\n",
        "for i, image_tensor in enumerate(z):\n",
        "    image_tensor = image_tensor.detach()\n",
        "    print(i,image_tensor)\n",
        "\n",
        "    # save the latent vector, related to the image\n",
        "    f = open('/content/s1/%d.txt' %i,'a')\n",
        "    f.write(np.array2string(image_tensor.numpy(), separator=','))\n",
        "    f.close()\n",
        "\n",
        "    # create image using latent vector\n",
        "    rand_image = G(image_tensor.to(device)) \n",
        "\n",
        "    # save image\n",
        "    rand_image = rand_image.view(-1, 28) # convert [784] tensor in to [28,28] tensor to create image\n",
        "    save_image(rand_image, '/content/s1/%d.png' %i, normalize = True)\n",
        "\n",
        "\n",
        "#create a zip file contains generated image files and Latent vectors\n",
        "import shutil\n",
        "shutil.make_archive('s1', 'zip', 's1')\n",
        "files.download('s1.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcORx3pmwI2M"
      },
      "source": [
        "**Create the real/s0 image set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "1g90rYaZoJJq",
        "outputId": "a076e3d5-eb31-43da-f607-230aa779d3d4"
      },
      "source": [
        "\n",
        "for idx, (img, _) in enumerate(train_dataset):\n",
        "    # save the latent vector, related to the image\n",
        "    f = open('/content/s0/%d.txt' %idx,'a')\n",
        "    f.write(np.array2string(img.numpy(), separator=','))\n",
        "    f.close()\n",
        "    save_image(img, '/content/s0/%d.png' %idx, normalize = True)\n",
        "    if idx == 100:\n",
        "        break   \n",
        "\n",
        "#create a zip file with generated image files and Latent vectors\n",
        "shutil.make_archive('s0', 'zip', 's0')\n",
        "files.download('s0.zip')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_c9c27460-9ac0-421f-9578-b38cdf2bc6a6\", \"s0.zip\", 135771)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giL4Oh3zP6r4"
      },
      "source": [
        "**Here folders need to created with labels and then need to upload for the classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4iSbv7sQCz2",
        "outputId": "bea77afb-f81d-48a3-a119-4b1121c5009d"
      },
      "source": [
        "!unzip '/content/s1.zip' -d '/content/fake'\n",
        "!unzip '/content/s0.zip' -d '/content/real'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/s1.zip\n",
            "   creating: /content/fake/s1/0/\n",
            " extracting: /content/fake/s1/0/1.png  \n",
            "  inflating: /content/fake/s1/0/1.txt  \n",
            " extracting: /content/fake/s1/0/21.png  \n",
            "  inflating: /content/fake/s1/0/21.txt  \n",
            " extracting: /content/fake/s1/0/34.png  \n",
            "  inflating: /content/fake/s1/0/34.txt  \n",
            " extracting: /content/fake/s1/0/37.png  \n",
            "  inflating: /content/fake/s1/0/37.txt  \n",
            " extracting: /content/fake/s1/0/51.png  \n",
            "  inflating: /content/fake/s1/0/51.txt  \n",
            " extracting: /content/fake/s1/0/56.png  \n",
            "  inflating: /content/fake/s1/0/56.txt  \n",
            " extracting: /content/fake/s1/0/63.png  \n",
            "  inflating: /content/fake/s1/0/63.txt  \n",
            " extracting: /content/fake/s1/0/68.png  \n",
            "  inflating: /content/fake/s1/0/68.txt  \n",
            " extracting: /content/fake/s1/0/69.png  \n",
            "  inflating: /content/fake/s1/0/69.txt  \n",
            " extracting: /content/fake/s1/0/75.png  \n",
            "  inflating: /content/fake/s1/0/75.txt  \n",
            " extracting: /content/fake/s1/0/81.png  \n",
            "  inflating: /content/fake/s1/0/81.txt  \n",
            "   creating: /content/fake/s1/1/\n",
            " extracting: /content/fake/s1/1/14.png  \n",
            "  inflating: /content/fake/s1/1/14.txt  \n",
            " extracting: /content/fake/s1/1/23.png  \n",
            "  inflating: /content/fake/s1/1/23.txt  \n",
            " extracting: /content/fake/s1/1/24.png  \n",
            "  inflating: /content/fake/s1/1/24.txt  \n",
            " extracting: /content/fake/s1/1/3.png  \n",
            "  inflating: /content/fake/s1/1/3.txt  \n",
            " extracting: /content/fake/s1/1/40.png  \n",
            "  inflating: /content/fake/s1/1/40.txt  \n",
            " extracting: /content/fake/s1/1/59.png  \n",
            "  inflating: /content/fake/s1/1/59.txt  \n",
            " extracting: /content/fake/s1/1/6.png  \n",
            "  inflating: /content/fake/s1/1/6.txt  \n",
            " extracting: /content/fake/s1/1/67.png  \n",
            "  inflating: /content/fake/s1/1/67.txt  \n",
            " extracting: /content/fake/s1/1/70.png  \n",
            "  inflating: /content/fake/s1/1/70.txt  \n",
            " extracting: /content/fake/s1/1/72.png  \n",
            "  inflating: /content/fake/s1/1/72.txt  \n",
            " extracting: /content/fake/s1/1/77.png  \n",
            "  inflating: /content/fake/s1/1/77.txt  \n",
            " extracting: /content/fake/s1/1/78.png  \n",
            "  inflating: /content/fake/s1/1/78.txt  \n",
            " extracting: /content/fake/s1/1/8.png  \n",
            "  inflating: /content/fake/s1/1/8.txt  \n",
            " extracting: /content/fake/s1/1/99.png  \n",
            "  inflating: /content/fake/s1/1/99.txt  \n",
            "   creating: /content/fake/s1/2/\n",
            " extracting: /content/fake/s1/2/25.png  \n",
            "  inflating: /content/fake/s1/2/25.txt  \n",
            " extracting: /content/fake/s1/2/28.png  \n",
            "  inflating: /content/fake/s1/2/28.txt  \n",
            " extracting: /content/fake/s1/2/5.png  \n",
            "  inflating: /content/fake/s1/2/5.txt  \n",
            " extracting: /content/fake/s1/2/76.png  \n",
            "  inflating: /content/fake/s1/2/76.txt  \n",
            " extracting: /content/fake/s1/2/82.png  \n",
            "  inflating: /content/fake/s1/2/82.txt  \n",
            "   creating: /content/fake/s1/3/\n",
            " extracting: /content/fake/s1/3/10.png  \n",
            "  inflating: /content/fake/s1/3/10.txt  \n",
            " extracting: /content/fake/s1/3/12.png  \n",
            "  inflating: /content/fake/s1/3/12.txt  \n",
            " extracting: /content/fake/s1/3/27.png  \n",
            "  inflating: /content/fake/s1/3/27.txt  \n",
            " extracting: /content/fake/s1/3/30.png  \n",
            "  inflating: /content/fake/s1/3/30.txt  \n",
            " extracting: /content/fake/s1/3/44.png  \n",
            "  inflating: /content/fake/s1/3/44.txt  \n",
            " extracting: /content/fake/s1/3/49.png  \n",
            "  inflating: /content/fake/s1/3/49.txt  \n",
            " extracting: /content/fake/s1/3/50.png  \n",
            "  inflating: /content/fake/s1/3/50.txt  \n",
            " extracting: /content/fake/s1/3/7.png  \n",
            "  inflating: /content/fake/s1/3/7.txt  \n",
            " extracting: /content/fake/s1/3/74.png  \n",
            "  inflating: /content/fake/s1/3/74.txt  \n",
            " extracting: /content/fake/s1/3/86.png  \n",
            "  inflating: /content/fake/s1/3/86.txt  \n",
            " extracting: /content/fake/s1/3/98.png  \n",
            "  inflating: /content/fake/s1/3/98.txt  \n",
            "   creating: /content/fake/s1/4/\n",
            " extracting: /content/fake/s1/4/2.png  \n",
            "  inflating: /content/fake/s1/4/2.txt  \n",
            " extracting: /content/fake/s1/4/53.png  \n",
            "  inflating: /content/fake/s1/4/53.txt  \n",
            " extracting: /content/fake/s1/4/58.png  \n",
            "  inflating: /content/fake/s1/4/58.txt  \n",
            " extracting: /content/fake/s1/4/60.png  \n",
            "  inflating: /content/fake/s1/4/60.txt  \n",
            " extracting: /content/fake/s1/4/61.png  \n",
            "  inflating: /content/fake/s1/4/61.txt  \n",
            " extracting: /content/fake/s1/4/64.png  \n",
            "  inflating: /content/fake/s1/4/64.txt  \n",
            " extracting: /content/fake/s1/4/89.png  \n",
            "  inflating: /content/fake/s1/4/89.txt  \n",
            " extracting: /content/fake/s1/4/9.png  \n",
            "  inflating: /content/fake/s1/4/9.txt  \n",
            " extracting: /content/fake/s1/4/92.png  \n",
            "  inflating: /content/fake/s1/4/92.txt  \n",
            "   creating: /content/fake/s1/5/\n",
            " extracting: /content/fake/s1/5/100.png  \n",
            "  inflating: /content/fake/s1/5/100.txt  \n",
            " extracting: /content/fake/s1/5/11.png  \n",
            "  inflating: /content/fake/s1/5/11.txt  \n",
            " extracting: /content/fake/s1/5/65.png  \n",
            "  inflating: /content/fake/s1/5/65.txt  \n",
            "   creating: /content/fake/s1/6/\n",
            " extracting: /content/fake/s1/6/13.png  \n",
            "  inflating: /content/fake/s1/6/13.txt  \n",
            " extracting: /content/fake/s1/6/18.png  \n",
            "  inflating: /content/fake/s1/6/18.txt  \n",
            " extracting: /content/fake/s1/6/32.png  \n",
            "  inflating: /content/fake/s1/6/32.txt  \n",
            " extracting: /content/fake/s1/6/36.png  \n",
            "  inflating: /content/fake/s1/6/36.txt  \n",
            " extracting: /content/fake/s1/6/39.png  \n",
            "  inflating: /content/fake/s1/6/39.txt  \n",
            " extracting: /content/fake/s1/6/83.png  \n",
            "  inflating: /content/fake/s1/6/83.txt  \n",
            " extracting: /content/fake/s1/6/90.png  \n",
            "  inflating: /content/fake/s1/6/90.txt  \n",
            "   creating: /content/fake/s1/7/\n",
            " extracting: /content/fake/s1/7/29.png  \n",
            "  inflating: /content/fake/s1/7/29.txt  \n",
            " extracting: /content/fake/s1/7/42.png  \n",
            "  inflating: /content/fake/s1/7/42.txt  \n",
            " extracting: /content/fake/s1/7/84.png  \n",
            "  inflating: /content/fake/s1/7/84.txt  \n",
            " extracting: /content/fake/s1/7/91.png  \n",
            "  inflating: /content/fake/s1/7/91.txt  \n",
            " extracting: /content/fake/s1/7/96.png  \n",
            "  inflating: /content/fake/s1/7/96.txt  \n",
            "   creating: /content/fake/s1/8/\n",
            " extracting: /content/fake/s1/8/31.png  \n",
            "  inflating: /content/fake/s1/8/31.txt  \n",
            " extracting: /content/fake/s1/8/41.png  \n",
            "  inflating: /content/fake/s1/8/41.txt  \n",
            " extracting: /content/fake/s1/8/46.png  \n",
            "  inflating: /content/fake/s1/8/46.txt  \n",
            " extracting: /content/fake/s1/8/55.png  \n",
            "  inflating: /content/fake/s1/8/55.txt  \n",
            " extracting: /content/fake/s1/8/85.png  \n",
            "  inflating: /content/fake/s1/8/85.txt  \n",
            " extracting: /content/fake/s1/8/94.png  \n",
            "  inflating: /content/fake/s1/8/94.txt  \n",
            "   creating: /content/fake/s1/9/\n",
            " extracting: /content/fake/s1/9/4.png  \n",
            "  inflating: /content/fake/s1/9/4.txt  \n",
            " extracting: /content/fake/s1/9/54.png  \n",
            "  inflating: /content/fake/s1/9/54.txt  \n",
            " extracting: /content/fake/s1/9/57.png  \n",
            "  inflating: /content/fake/s1/9/57.txt  \n",
            " extracting: /content/fake/s1/9/80.png  \n",
            "  inflating: /content/fake/s1/9/80.txt  \n",
            " extracting: /content/fake/s1/9/87.png  \n",
            "  inflating: /content/fake/s1/9/87.txt  \n",
            "Archive:  /content/s0.zip\n",
            "   creating: /content/real/s0/0/\n",
            " extracting: /content/real/s0/0/100.png  \n",
            "  inflating: /content/real/s0/0/100.txt  \n",
            " extracting: /content/real/s0/0/106.png  \n",
            "  inflating: /content/real/s0/0/106.txt  \n",
            " extracting: /content/real/s0/0/127.png  \n",
            "  inflating: /content/real/s0/0/127.txt  \n",
            " extracting: /content/real/s0/0/158.png  \n",
            "  inflating: /content/real/s0/0/158.txt  \n",
            " extracting: /content/real/s0/0/170.png  \n",
            "  inflating: /content/real/s0/0/170.txt  \n",
            " extracting: /content/real/s0/0/183.png  \n",
            "  inflating: /content/real/s0/0/183.txt  \n",
            " extracting: /content/real/s0/0/192.png  \n",
            "  inflating: /content/real/s0/0/192.txt  \n",
            " extracting: /content/real/s0/0/8.png  \n",
            "  inflating: /content/real/s0/0/8.txt  \n",
            " extracting: /content/real/s0/0/84.png  \n",
            "  inflating: /content/real/s0/0/84.txt  \n",
            " extracting: /content/real/s0/0/90.png  \n",
            "  inflating: /content/real/s0/0/90.txt  \n",
            "   creating: /content/real/s0/1/\n",
            " extracting: /content/real/s0/1/135.png  \n",
            "  inflating: /content/real/s0/1/135.txt  \n",
            " extracting: /content/real/s0/1/15.png  \n",
            "  inflating: /content/real/s0/1/15.txt  \n",
            " extracting: /content/real/s0/1/160.png  \n",
            "  inflating: /content/real/s0/1/160.txt  \n",
            " extracting: /content/real/s0/1/19.png  \n",
            "  inflating: /content/real/s0/1/19.txt  \n",
            " extracting: /content/real/s0/1/194.png  \n",
            "  inflating: /content/real/s0/1/194.txt  \n",
            " extracting: /content/real/s0/1/23.png  \n",
            "  inflating: /content/real/s0/1/23.txt  \n",
            " extracting: /content/real/s0/1/65.png  \n",
            "  inflating: /content/real/s0/1/65.txt  \n",
            " extracting: /content/real/s0/1/83.png  \n",
            "  inflating: /content/real/s0/1/83.txt  \n",
            " extracting: /content/real/s0/1/93.png  \n",
            "  inflating: /content/real/s0/1/93.txt  \n",
            "   creating: /content/real/s0/2/\n",
            " extracting: /content/real/s0/2/125.png  \n",
            "  inflating: /content/real/s0/2/125.txt  \n",
            " extracting: /content/real/s0/2/132.png  \n",
            "  inflating: /content/real/s0/2/132.txt  \n",
            " extracting: /content/real/s0/2/159.png  \n",
            "  inflating: /content/real/s0/2/159.txt  \n",
            " extracting: /content/real/s0/2/175.png  \n",
            "  inflating: /content/real/s0/2/175.txt  \n",
            " extracting: /content/real/s0/2/30.png  \n",
            "  inflating: /content/real/s0/2/30.txt  \n",
            " extracting: /content/real/s0/2/32.png  \n",
            "  inflating: /content/real/s0/2/32.txt  \n",
            " extracting: /content/real/s0/2/6.png  \n",
            "  inflating: /content/real/s0/2/6.txt  \n",
            " extracting: /content/real/s0/2/69.png  \n",
            "  inflating: /content/real/s0/2/69.txt  \n",
            "   creating: /content/real/s0/3/\n",
            " extracting: /content/real/s0/3/105.png  \n",
            "  inflating: /content/real/s0/3/105.txt  \n",
            " extracting: /content/real/s0/3/110.png  \n",
            "  inflating: /content/real/s0/3/110.txt  \n",
            " extracting: /content/real/s0/3/139.png  \n",
            "  inflating: /content/real/s0/3/139.txt  \n",
            " extracting: /content/real/s0/3/14.png  \n",
            "  inflating: /content/real/s0/3/14.txt  \n",
            " extracting: /content/real/s0/3/141.png  \n",
            "  inflating: /content/real/s0/3/141.txt  \n",
            " extracting: /content/real/s0/3/145.png  \n",
            "  inflating: /content/real/s0/3/145.txt  \n",
            " extracting: /content/real/s0/3/150.png  \n",
            "  inflating: /content/real/s0/3/150.txt  \n",
            " extracting: /content/real/s0/3/152.png  \n",
            "  inflating: /content/real/s0/3/152.txt  \n",
            " extracting: /content/real/s0/3/169.png  \n",
            "  inflating: /content/real/s0/3/169.txt  \n",
            " extracting: /content/real/s0/3/171.png  \n",
            "  inflating: /content/real/s0/3/171.txt  \n",
            " extracting: /content/real/s0/3/174.png  \n",
            "  inflating: /content/real/s0/3/174.txt  \n",
            " extracting: /content/real/s0/3/182.png  \n",
            "  inflating: /content/real/s0/3/182.txt  \n",
            " extracting: /content/real/s0/3/188.png  \n",
            "  inflating: /content/real/s0/3/188.txt  \n",
            " extracting: /content/real/s0/3/189.png  \n",
            "  inflating: /content/real/s0/3/189.txt  \n",
            " extracting: /content/real/s0/3/27.png  \n",
            "  inflating: /content/real/s0/3/27.txt  \n",
            " extracting: /content/real/s0/3/37.png  \n",
            "  inflating: /content/real/s0/3/37.txt  \n",
            " extracting: /content/real/s0/3/45.png  \n",
            "  inflating: /content/real/s0/3/45.txt  \n",
            " extracting: /content/real/s0/3/51.png  \n",
            "  inflating: /content/real/s0/3/51.txt  \n",
            " extracting: /content/real/s0/3/64.png  \n",
            "  inflating: /content/real/s0/3/64.txt  \n",
            " extracting: /content/real/s0/3/92.png  \n",
            "  inflating: /content/real/s0/3/92.txt  \n",
            " extracting: /content/real/s0/3/95.png  \n",
            "  inflating: /content/real/s0/3/95.txt  \n",
            " extracting: /content/real/s0/3/99.png  \n",
            "  inflating: /content/real/s0/3/99.txt  \n",
            "   creating: /content/real/s0/4/\n",
            " extracting: /content/real/s0/4/156.png  \n",
            "  inflating: /content/real/s0/4/156.txt  \n",
            " extracting: /content/real/s0/4/177.png  \n",
            "  inflating: /content/real/s0/4/177.txt  \n",
            " extracting: /content/real/s0/4/42.png  \n",
            "  inflating: /content/real/s0/4/42.txt  \n",
            " extracting: /content/real/s0/4/5.png  \n",
            "  inflating: /content/real/s0/4/5.txt  \n",
            " extracting: /content/real/s0/4/68.png  \n",
            "  inflating: /content/real/s0/4/68.txt  \n",
            " extracting: /content/real/s0/4/71.png  \n",
            "  inflating: /content/real/s0/4/71.txt  \n",
            " extracting: /content/real/s0/4/78.png  \n",
            "  inflating: /content/real/s0/4/78.txt  \n",
            "   creating: /content/real/s0/5/\n",
            " extracting: /content/real/s0/5/107.png  \n",
            "  inflating: /content/real/s0/5/107.txt  \n",
            " extracting: /content/real/s0/5/144.png  \n",
            "  inflating: /content/real/s0/5/144.txt  \n",
            " extracting: /content/real/s0/5/149.png  \n",
            "  inflating: /content/real/s0/5/149.txt  \n",
            " extracting: /content/real/s0/5/153.png  \n",
            "  inflating: /content/real/s0/5/153.txt  \n",
            " extracting: /content/real/s0/5/167.png  \n",
            "  inflating: /content/real/s0/5/167.txt  \n",
            " extracting: /content/real/s0/5/26.png  \n",
            "  inflating: /content/real/s0/5/26.txt  \n",
            " extracting: /content/real/s0/5/53.png  \n",
            "  inflating: /content/real/s0/5/53.txt  \n",
            "   creating: /content/real/s0/6/\n",
            " extracting: /content/real/s0/6/164.png  \n",
            "  inflating: /content/real/s0/6/164.txt  \n",
            " extracting: /content/real/s0/6/193.png  \n",
            "  inflating: /content/real/s0/6/193.txt  \n",
            " extracting: /content/real/s0/6/2.png  \n",
            "  inflating: /content/real/s0/6/2.txt  \n",
            "   creating: /content/real/s0/7/\n",
            " extracting: /content/real/s0/7/123.png  \n",
            "  inflating: /content/real/s0/7/123.txt  \n",
            " extracting: /content/real/s0/7/146.png  \n",
            "  inflating: /content/real/s0/7/146.txt  \n",
            " extracting: /content/real/s0/7/178.png  \n",
            "  inflating: /content/real/s0/7/178.txt  \n",
            " extracting: /content/real/s0/7/28.png  \n",
            "  inflating: /content/real/s0/7/28.txt  \n",
            " extracting: /content/real/s0/7/3.png  \n",
            "  inflating: /content/real/s0/7/3.txt  \n",
            " extracting: /content/real/s0/7/41.png  \n",
            "  inflating: /content/real/s0/7/41.txt  \n",
            " extracting: /content/real/s0/7/55.png  \n",
            "  inflating: /content/real/s0/7/55.txt  \n",
            " extracting: /content/real/s0/7/57.png  \n",
            "  inflating: /content/real/s0/7/57.txt  \n",
            " extracting: /content/real/s0/7/70.png  \n",
            "  inflating: /content/real/s0/7/70.txt  \n",
            " extracting: /content/real/s0/7/76.png  \n",
            "  inflating: /content/real/s0/7/76.txt  \n",
            " extracting: /content/real/s0/7/86.png  \n",
            "  inflating: /content/real/s0/7/86.txt  \n",
            " extracting: /content/real/s0/7/89.png  \n",
            "  inflating: /content/real/s0/7/89.txt  \n",
            "   creating: /content/real/s0/8/\n",
            " extracting: /content/real/s0/8/10.png  \n",
            "  inflating: /content/real/s0/8/10.txt  \n",
            " extracting: /content/real/s0/8/154.png  \n",
            "  inflating: /content/real/s0/8/154.txt  \n",
            " extracting: /content/real/s0/8/180.png  \n",
            "  inflating: /content/real/s0/8/180.txt  \n",
            " extracting: /content/real/s0/8/20.png  \n",
            "  inflating: /content/real/s0/8/20.txt  \n",
            " extracting: /content/real/s0/8/36.png  \n",
            "  inflating: /content/real/s0/8/36.txt  \n",
            " extracting: /content/real/s0/8/9.png  \n",
            "  inflating: /content/real/s0/8/9.txt  \n",
            "   creating: /content/real/s0/9/\n",
            " extracting: /content/real/s0/9/108.png  \n",
            "  inflating: /content/real/s0/9/108.txt  \n",
            " extracting: /content/real/s0/9/122.png  \n",
            "  inflating: /content/real/s0/9/122.txt  \n",
            " extracting: /content/real/s0/9/128.png  \n",
            "  inflating: /content/real/s0/9/128.txt  \n",
            " extracting: /content/real/s0/9/138.png  \n",
            "  inflating: /content/real/s0/9/138.txt  \n",
            " extracting: /content/real/s0/9/151.png  \n",
            "  inflating: /content/real/s0/9/151.txt  \n",
            " extracting: /content/real/s0/9/155.png  \n",
            "  inflating: /content/real/s0/9/155.txt  \n",
            " extracting: /content/real/s0/9/162.png  \n",
            "  inflating: /content/real/s0/9/162.txt  \n",
            " extracting: /content/real/s0/9/163.png  \n",
            "  inflating: /content/real/s0/9/163.txt  \n",
            " extracting: /content/real/s0/9/165.png  \n",
            "  inflating: /content/real/s0/9/165.txt  \n",
            " extracting: /content/real/s0/9/166.png  \n",
            "  inflating: /content/real/s0/9/166.txt  \n",
            " extracting: /content/real/s0/9/168.png  \n",
            "  inflating: /content/real/s0/9/168.txt  \n",
            " extracting: /content/real/s0/9/173.png  \n",
            "  inflating: /content/real/s0/9/173.txt  \n",
            " extracting: /content/real/s0/9/191.png  \n",
            "  inflating: /content/real/s0/9/191.txt  \n",
            " extracting: /content/real/s0/9/196.png  \n",
            "  inflating: /content/real/s0/9/196.txt  \n",
            " extracting: /content/real/s0/9/198.png  \n",
            "  inflating: /content/real/s0/9/198.txt  \n",
            " extracting: /content/real/s0/9/38.png  \n",
            "  inflating: /content/real/s0/9/38.txt  \n",
            " extracting: /content/real/s0/9/40.png  \n",
            "  inflating: /content/real/s0/9/40.txt  \n",
            " extracting: /content/real/s0/9/50.png  \n",
            "  inflating: /content/real/s0/9/50.txt  \n",
            " extracting: /content/real/s0/9/52.png  \n",
            "  inflating: /content/real/s0/9/52.txt  \n",
            " extracting: /content/real/s0/9/54.png  \n",
            "  inflating: /content/real/s0/9/54.txt  \n",
            " extracting: /content/real/s0/9/63.png  \n",
            "  inflating: /content/real/s0/9/63.txt  \n",
            " extracting: /content/real/s0/9/74.png  \n",
            "  inflating: /content/real/s0/9/74.txt  \n",
            " extracting: /content/real/s0/9/75.png  \n",
            "  inflating: /content/real/s0/9/75.txt  \n",
            " extracting: /content/real/s0/9/87.png  \n",
            "  inflating: /content/real/s0/9/87.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzhyJoCMT7bj"
      },
      "source": [
        "s0_path ='/content/real/s0'\n",
        "s1_path ='/content/fake/s1'\n",
        "\n",
        "train_data=datasets.ImageFolder(\n",
        "    root=s0_path,\n",
        "    transform=transforms.Compose([transforms.Grayscale(),transforms.ToTensor()])\n",
        ")\n",
        "\n",
        "\n",
        "test_data=datasets.ImageFolder(\n",
        "    root=s1_path,\n",
        "    transform=transforms.Compose([transforms.Grayscale(),transforms.ToTensor()])\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3ZEZMNbUowR"
      },
      "source": [
        "**Get the data to the data loader**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkwVOgduUpki",
        "outputId": "17517ed6-1fb9-46c8-92bf-27c044ec1678"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "loaders = {\n",
        "    'train' : torch.utils.data.DataLoader(train_data, \n",
        "                                          batch_size=100, \n",
        "                                          shuffle=True, \n",
        "                                          num_workers=1),\n",
        "    \n",
        "    'test'  : torch.utils.data.DataLoader(test_data, \n",
        "                                          batch_size=100, \n",
        "                                          shuffle=True, \n",
        "                                          num_workers=1),\n",
        "}\n",
        "loaders"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test': <torch.utils.data.dataloader.DataLoader at 0x7f2ee9d8cc50>,\n",
              " 'train': <torch.utils.data.dataloader.DataLoader at 0x7f2ee9d8ced0>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBkP2O4dUzpu"
      },
      "source": [
        "**Classifier** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMMQA3V8U2ZG"
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Sequential(         \n",
        "            nn.Conv2d(\n",
        "                in_channels=1,              \n",
        "                out_channels=36,  #16          \n",
        "                kernel_size=5,              \n",
        "                stride=1,                   \n",
        "                padding=2,                  \n",
        "            ),                              \n",
        "            nn.ReLU(),                      \n",
        "            nn.MaxPool2d(kernel_size=2),    \n",
        "        )\n",
        "        self.conv2 = nn.Sequential(         \n",
        "            nn.Conv2d(36, 32, 5, 1, 2),     \n",
        "            nn.ReLU(),                      \n",
        "            nn.MaxPool2d(2),                \n",
        "        )\n",
        "        # fully connected layer, output 10 classes\n",
        "        self.out = nn.Linear(32 * 7 * 7, 10)\n",
        "\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
        "        x = x.view(x.size(0), -1)       \n",
        "        output = self.out(x)\n",
        "        return output, x    # return x for visualization\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2a7KTpMU-gc",
        "outputId": "96b8ef79-d6a1-4c48-8069-813eb937b6b4"
      },
      "source": [
        "cnn=CNN()\n",
        "print(cnn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CNN(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(1, 36, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(36, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (out): Linear(in_features=1568, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1UmAqQeVBq-"
      },
      "source": [
        "**Loss function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shRptkB1U_Mj",
        "outputId": "ba961d35-56d9-48c6-d65c-07e314a0043d"
      },
      "source": [
        "loss_func = nn.CrossEntropyLoss()\n",
        "loss_func"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CrossEntropyLoss()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doc1wE-3VONA"
      },
      "source": [
        "**Optimizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-1UFWRPVRuk",
        "outputId": "d663af6a-8653-42ad-ff67-385bca25e591"
      },
      "source": [
        "optimizer = optim.Adam(cnn.parameters(), lr=0.01)\n",
        "optimizer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Adam (\n",
              "Parameter Group 0\n",
              "    amsgrad: False\n",
              "    betas: (0.9, 0.999)\n",
              "    eps: 1e-08\n",
              "    lr: 0.01\n",
              "    weight_decay: 0\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjfDobU4VY-Y"
      },
      "source": [
        "**Train data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_W_4oC1UVa7G",
        "outputId": "3e9fbd90-4096-4dc9-b852-73d56e789e79"
      },
      "source": [
        "num_epochs = 10\n",
        "\n",
        "def train(num_epochs, cnn, loaders):\n",
        "    \n",
        "    cnn.train()\n",
        "        \n",
        "    # Train the model\n",
        "    total_step = len(loaders['train'])\n",
        "        \n",
        "    for epoch in range(num_epochs):\n",
        "        correct = 0;\n",
        "        total = 0;\n",
        "        for i, (images, labels) in enumerate(loaders['train']):\n",
        "            total=total+1\n",
        "            # gives batch data, normalize x when iterate train_loader\n",
        "            b_x = Variable(images)   # batch x\n",
        "            b_y = Variable(labels)   # batch y\n",
        "            output = cnn(b_x)[0]\n",
        "            output_label = torch.max(output,1)[1].data.squeeze()\n",
        "            loss = loss_func(output, b_y)             \n",
        "            accuracy=(output_label==b_y).sum().item()/float(b_y.size(0))\n",
        "           \n",
        "            \n",
        "            # clear gradients for this training step   \n",
        "            optimizer.zero_grad()           \n",
        "            \n",
        "            # backpropagation, compute gradients \n",
        "            loss.backward()    \n",
        "            # apply gradients             \n",
        "            optimizer.step()                \n",
        "            \n",
        "            \n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))\n",
        "            print('Training Acc. %.2f' % accuracy)\n",
        "            \n",
        "        pass\n",
        "    pass\n",
        "\n",
        "train(num_epochs, cnn, loaders)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [1/2], Loss: 0.7915\n",
            "Training Acc. 0.71\n",
            "Epoch [1/10], Step [2/2], Loss: 0.5134\n",
            "Training Acc. 0.75\n",
            "Epoch [2/10], Step [1/2], Loss: 0.5696\n",
            "Training Acc. 0.78\n",
            "Epoch [2/10], Step [2/2], Loss: 0.1315\n",
            "Training Acc. 1.00\n",
            "Epoch [3/10], Step [1/2], Loss: 0.4532\n",
            "Training Acc. 0.86\n",
            "Epoch [3/10], Step [2/2], Loss: 0.2690\n",
            "Training Acc. 1.00\n",
            "Epoch [4/10], Step [1/2], Loss: 0.3545\n",
            "Training Acc. 0.89\n",
            "Epoch [4/10], Step [2/2], Loss: 0.0521\n",
            "Training Acc. 1.00\n",
            "Epoch [5/10], Step [1/2], Loss: 0.3530\n",
            "Training Acc. 0.88\n",
            "Epoch [5/10], Step [2/2], Loss: 0.2591\n",
            "Training Acc. 0.88\n",
            "Epoch [6/10], Step [1/2], Loss: 0.2291\n",
            "Training Acc. 0.92\n",
            "Epoch [6/10], Step [2/2], Loss: 0.2582\n",
            "Training Acc. 0.88\n",
            "Epoch [7/10], Step [1/2], Loss: 0.2529\n",
            "Training Acc. 0.91\n",
            "Epoch [7/10], Step [2/2], Loss: 0.1457\n",
            "Training Acc. 1.00\n",
            "Epoch [8/10], Step [1/2], Loss: 0.1835\n",
            "Training Acc. 0.94\n",
            "Epoch [8/10], Step [2/2], Loss: 0.2483\n",
            "Training Acc. 0.88\n",
            "Epoch [9/10], Step [1/2], Loss: 0.1390\n",
            "Training Acc. 0.95\n",
            "Epoch [9/10], Step [2/2], Loss: 0.0482\n",
            "Training Acc. 1.00\n",
            "Epoch [10/10], Step [1/2], Loss: 0.1465\n",
            "Training Acc. 0.95\n",
            "Epoch [10/10], Step [2/2], Loss: 0.0071\n",
            "Training Acc. 1.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkkJjJW8Vodx"
      },
      "source": [
        "**Test data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6eCBTEdVqaK",
        "outputId": "d865d778-88a8-4ea8-b41b-22b2ff1f8026"
      },
      "source": [
        "def test():\n",
        "  cnn.eval()\n",
        "  with torch.no_grad():\n",
        "    correct=0\n",
        "    total=0\n",
        "    for images, labels in loaders['test']:\n",
        "      test_output,last_layer=cnn(images)\n",
        "      pred_y=torch.max(test_output,1)[1].data.squeeze()\n",
        "      accuracy=(pred_y==labels).sum().item()/float(labels.size(0))\n",
        "      pass\n",
        "    print('Test Acc %.2f' % accuracy)\n",
        "    pass\n",
        "\n",
        "\n",
        "test()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Acc 0.82\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_GTRZacbOfs"
      },
      "source": [
        "**Save the classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "A4BT3NgLbRQc",
        "outputId": "4bc44ee6-1ba2-4f03-c7c3-7549ba788b17"
      },
      "source": [
        "# Save the classifier\n",
        "with open('C.pkl', 'wb') as f:\n",
        "    pkl.dump(cnn, f)\n",
        "\n",
        "\n",
        "# download the classifier model\n",
        "files.download('C.pkl')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_65d40b1f-5e9c-445a-b684-ec1f26822393\", \"C.pkl\", 185847)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}