{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNU3ubiJEodCB1rDJ80mJcw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UthpalaPitawela/Data_Science_Implementations/blob/main/Text_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8duquAIHWbiZ"
      },
      "source": [
        "Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juRn38e1WfCH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9610d4ce-ad93-4314-8668-c137e22b86b8"
      },
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "#libraries for pre processing\n",
        "from bs4 import BeautifulSoup\n",
        "!pip install contractions\n",
        "import contractions\n",
        "import re\n",
        "import string\n",
        "#to remove stop words\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import ToktokTokenizer\n",
        "tokenizer = ToktokTokenizer()\n",
        "stopword_list = nltk.corpus.stopwords.words('english')\n",
        "# custom: removing words from list\n",
        "stopword_list.remove('not')\n",
        "\n",
        "#for lemmatization\n",
        "import spacy\n",
        "nlp = spacy.load('en',parse=True,tag=True, entity=True)\n",
        "\n",
        "#libraries for feature extraction\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "NER = spacy.load(\"en_core_web_sm\")\n",
        "from nltk import pos_tag\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "#libraries for evaluation metrics\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "#libraries for SVM\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting contractions\n",
            "  Downloading contractions-0.0.52-py2.py3-none-any.whl (7.2 kB)\n",
            "Collecting textsearch>=0.0.21\n",
            "  Downloading textsearch-0.0.21-py2.py3-none-any.whl (7.5 kB)\n",
            "Collecting anyascii\n",
            "  Downloading anyascii-0.2.0-py3-none-any.whl (283 kB)\n",
            "\u001b[K     |████████████████████████████████| 283 kB 5.7 MB/s \n",
            "\u001b[?25hCollecting pyahocorasick\n",
            "  Downloading pyahocorasick-1.4.2.tar.gz (321 kB)\n",
            "\u001b[K     |████████████████████████████████| 321 kB 45.0 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyahocorasick\n",
            "  Building wheel for pyahocorasick (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyahocorasick: filename=pyahocorasick-1.4.2-cp37-cp37m-linux_x86_64.whl size=85448 sha256=772e16943cd561ff0278803cc8a0f3e4d778c5f724908954a1398ee3160a3336\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/19/a6/8f363d9939162782bb8439d886469756271abc01f76fbd790f\n",
            "Successfully built pyahocorasick\n",
            "Installing collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.2.0 contractions-0.0.52 pyahocorasick-1.4.2 textsearch-0.0.21\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGv3u1o6XV0l"
      },
      "source": [
        "#for word embeddings\n",
        "!git clone https://github.com/facebookresearch/fastText.git\n",
        "!cd fastText\n",
        "!pip install fastText\n",
        "import fasttext.util\n",
        "fasttext.util.download_model('en', if_exists='ignore')  # English\n",
        "ft = fasttext.load_model('cc.en.300.bin')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9riK56uL93u"
      },
      "source": [
        "Data load from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WzwcqSoLDGS"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "file_id = '1FJYN3RvVIe_zb1XL8w7pbuXRv3S6O38S'\n",
        "downloaded = drive.CreateFile({'id': file_id})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzV_s6kjUENd"
      },
      "source": [
        "# Download the file to a local disk as 'dataset.xlsx'.\n",
        "downloaded.GetContentFile('dataset.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9AOSZXxUa1N",
        "outputId": "e43c15c9-ff39-43ef-8656-57486c37609c"
      },
      "source": [
        "# Here it is --\n",
        "!ls -lha dataset.xlsx"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 232K Sep  2 02:37 dataset.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "8PX2cfkSUfAr",
        "outputId": "5485733c-d38d-4631-d7ae-5e1523e81ddf"
      },
      "source": [
        "# Now, we can use pandas read_excel after installing the excel importer.\n",
        "!pip install -q xlrd\n",
        "\n",
        "import pandas as pd\n",
        "columns = ['question', 'coarse', 'fine']\n",
        "df = pd.read_excel('dataset.xlsx', header=None,names=columns)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>coarse</th>\n",
              "      <th>fine</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What are the special things we (husband and me...</td>\n",
              "      <td>TTD</td>\n",
              "      <td>TTDSIG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What are the companies which organize shark fe...</td>\n",
              "      <td>TTD</td>\n",
              "      <td>TTDOTH</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Is it safe for female traveller to go alone to...</td>\n",
              "      <td>TGU</td>\n",
              "      <td>TGUHEA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What are the best places around Cape Town for ...</td>\n",
              "      <td>TTD</td>\n",
              "      <td>TTDSIG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What are the best places to stay for a family ...</td>\n",
              "      <td>ACM</td>\n",
              "      <td>ACMOTH</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>What is the best area to be based for sightsee...</td>\n",
              "      <td>TTD</td>\n",
              "      <td>TTDSIG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>What are the good value traditional bars and r...</td>\n",
              "      <td>FOD</td>\n",
              "      <td>FODBAR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>What are the hotels near Alicante bus station?</td>\n",
              "      <td>ACM</td>\n",
              "      <td>ACMHOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>Where to stay in La Gomera to mountain biking?</td>\n",
              "      <td>TTD</td>\n",
              "      <td>TTDSPO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>Is it possible to take a train trip from Santi...</td>\n",
              "      <td>TRS</td>\n",
              "      <td>TRSTRN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               question coarse    fine\n",
              "0     What are the special things we (husband and me...    TTD  TTDSIG\n",
              "1     What are the companies which organize shark fe...    TTD  TTDOTH\n",
              "2     Is it safe for female traveller to go alone to...    TGU  TGUHEA\n",
              "3     What are the best places around Cape Town for ...    TTD  TTDSIG\n",
              "4     What are the best places to stay for a family ...    ACM  ACMOTH\n",
              "...                                                 ...    ...     ...\n",
              "4995  What is the best area to be based for sightsee...    TTD  TTDSIG\n",
              "4996  What are the good value traditional bars and r...    FOD  FODBAR\n",
              "4997     What are the hotels near Alicante bus station?    ACM  ACMHOT\n",
              "4998     Where to stay in La Gomera to mountain biking?    TTD  TTDSPO\n",
              "4999  Is it possible to take a train trip from Santi...    TRS  TRSTRN\n",
              "\n",
              "[5000 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_T445BRdoWBf"
      },
      "source": [
        "Pre processing\n",
        "\n",
        "\n",
        "*   Remove HTML tags\n",
        "*   Expand contractions\n",
        "*   Remove special cases\n",
        "*   Lowercase all texts\n",
        "*   Remove stop words\n",
        "*   Lemmatization\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yU-Ek0go6Ui"
      },
      "source": [
        "Remove HTML tags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "JddFXsHeo3sj",
        "outputId": "1fe3654f-4b24-4ac9-ff92-0812ca3b9e69"
      },
      "source": [
        "def strip_html_tags(text):\n",
        "    \"\"\"remove html tags from text\"\"\"\n",
        "    soup = BeautifulSoup(text, \"html.parser\")\n",
        "    stripped_text = soup.get_text(separator=\" \")\n",
        "    return stripped_text\n",
        "\n",
        "\n",
        "df['html_removed_questions'] = [strip_html_tags(question) for question in df['question']]\n",
        "df['html_removed_questions'][1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'What are the companies which organize shark feeding events for scuba divers?'"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAHJlIOKbxTy"
      },
      "source": [
        "Expand contractions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-CMCMLldeih",
        "outputId": "1ddd90d3-85c5-41ee-af47-4ede28e3bc9d"
      },
      "source": [
        "def expand_contractions(text):\n",
        "    \"\"\"expand shortened words, e.g. don't to do not\"\"\"\n",
        "    text = contractions.fix(text)\n",
        "    return text\n",
        "\n",
        "item = \"What are the best tourist excursions when it's raining?\";\n",
        "\n",
        "df['contractions_removed_questions'] = [expand_contractions(question) for question in df['html_removed_questions']]\n",
        "print(item);\n",
        "print(expand_contractions(item));\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What are the best tourist excursions when it's raining?\n",
            "What are the best tourist excursions when it is raining?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xop8npTZf0X3"
      },
      "source": [
        "Remove special cases and punctuation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2SDgT5-fz13",
        "outputId": "685ede2b-e007-448a-f587-731f87c458e7"
      },
      "source": [
        "# function to remove special characters\n",
        "def remove_special_characters_punctuation(text):\n",
        "    # define the pattern to keep\n",
        "    pat = r'[^a-zA-z.,!?/:;\\\"\\'\\s\\n]' \n",
        "    formattedText = re.sub(pat, '', text)\n",
        "    text = ''.join([c for c in formattedText if c not in string.punctuation])\n",
        "    return text\n",
        "    \n",
        "item = \"What are the best tourist excursions when it's raining?\";\n",
        "\n",
        "df['special_characters_removed_questions'] = [remove_special_characters_punctuation(question) for question in df['contractions_removed_questions']]\n",
        "print(item);\n",
        "print(remove_special_characters_punctuation(item));"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What are the best tourist excursions when it's raining?\n",
            "What are the best tourist excursions when its raining\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYxOkpqbiOQ3"
      },
      "source": [
        "Lower case text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-tWdzNeidmF",
        "outputId": "dae2a7b6-3979-4951-e303-23dd3f2923bb"
      },
      "source": [
        "def lower_case_text(text):\n",
        "  text = text.strip().lower()\n",
        "  return text;\n",
        "\n",
        "item = \"Does anyone have the e-mail address for the Ambre resort & spa Mauritius?\";\n",
        "\n",
        "df['lower_cased_questions'] = [lower_case_text(question) for question in df['special_characters_removed_questions']]\n",
        "print(item);\n",
        "print(lower_case_text(item));\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Does anyone have the e-mail address for the Ambre resort & spa Mauritius?\n",
            "does anyone have the e-mail address for the ambre resort & spa mauritius?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcY_rsgri5oQ"
      },
      "source": [
        "Remove stop words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2dTc7Eai9FH",
        "outputId": "4a5115a4-977a-447d-91b7-d7bb76a57070"
      },
      "source": [
        "# function to remove stopwords\n",
        "def remove_stopwords(text):\n",
        "    # convert sentence into token of words\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    tokens = [token.strip() for token in tokens]\n",
        "    # check in lowercase \n",
        "    t = [token for token in tokens if token.lower() not in stopword_list]\n",
        "    text = ' '.join(t)    \n",
        "    return text\n",
        "\n",
        "item = \"What is the ideal time to visit Mauritius in the year as we are planning to get married in there and spend our honeymoon?\";\n",
        "df['stop_words_removed_questions'] = [remove_stopwords(question) for question in df['lower_cased_questions']]\n",
        "print(item);\n",
        "print(remove_stopwords(item));"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is the ideal time to visit Mauritius in the year as we are planning to get married in there and spend our honeymoon?\n",
            "ideal time visit Mauritius year planning get married spend honeymoon ?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZGS0L8NHb_y"
      },
      "source": [
        "Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0iuVzJckK_h",
        "outputId": "d1b51a5a-ec22-4ed4-fb44-1ff54ac552b1"
      },
      "source": [
        "def get_lem(text):\n",
        "    text = nlp(text)\n",
        "    text = ' '.join([word.lemma_ if word.lemma_ != '-PRON-' else word.text for word in text])\n",
        "    return text\n",
        "  \n",
        "item = \"What is the ideal time to visit Mauritius in the year as we are planning to get married in there and spend our honeymoon?\";\n",
        "df['lemmatized_questions'] = [get_lem(question) for question in df['stop_words_removed_questions']]\n",
        "print(item);\n",
        "print(get_lem(item));"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is the ideal time to visit Mauritius in the year as we are planning to get married in there and spend our honeymoon?\n",
            "what be the ideal time to visit Mauritius in the year as we be plan to get marry in there and spend our honeymoon ?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SB3YguYqkITK"
      },
      "source": [
        "Create Features\n",
        "\n",
        "*   POS tags\n",
        "*   Named Entities\n",
        "*   Head Word Synonyms\n",
        "*   Bi-grams\n",
        "*   Head words\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvZRCJHakH-w"
      },
      "source": [
        "POS Tags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOHiVS2kSWEO",
        "outputId": "23ffdf0a-9a65-401b-8f3c-20d82907531e"
      },
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "def pos_tagging(text):\n",
        "    words = nltk.word_tokenize(text)\n",
        "    lst = [ r[1] for r in pos_tag(words)] \n",
        "    return ' '.join(lst)\n",
        "\n",
        "\n",
        "item = \"What is the ideal time to visit Mauritius in the year as we are planning to get married in there and spend our honeymoon?\";\n",
        "df['pos_tagged_questions'] = [pos_tagging(question) for question in df['stop_words_removed_questions']]\n",
        "print(pos_tagging(item));\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "WP VBZ DT JJ NN TO VB NNP IN DT NN IN PRP VBP VBG TO VB VBN IN EX CC VB PRP$ NN .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78v-dqAR-ze3"
      },
      "source": [
        "Named Entities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNOg1K17K6EA",
        "outputId": "3213830c-393b-431d-cb66-43667ae57b7c"
      },
      "source": [
        "def getNamedEntities(text):\n",
        "  NER_text = NER(text);\n",
        "  NER_chunk = [];\n",
        "  for word in NER_text.ents:\n",
        "    label  = word.label_;\n",
        "    if label not in NER_chunk:\n",
        "      NER_chunk.append(word.label_)\n",
        "  def remove_null(x):\n",
        "        if '' in x:\n",
        "            x.remove('')\n",
        "        return x\n",
        "  lst = remove_null(NER_chunk)\n",
        "  return ' '.join(lst)\n",
        "  \n",
        "item = \"What is the ideal time to visit Mauritius in the year as we are planning to get married in there and spend our honeymoon?\";\n",
        "df['named_entity_questions'] = [getNamedEntities(question) for question in df['stop_words_removed_questions']]\n",
        "print(getNamedEntities(item));\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPE DATE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vXJO7YhlkJr"
      },
      "source": [
        "Count vectorizer (BOW)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fI8N19wfllec",
        "outputId": "9018b4de-341f-48ac-bd45-6c874e61acb1"
      },
      "source": [
        "def get_count_vect(documents):\n",
        "    vectorizer = CountVectorizer(max_features=1500, min_df=5, max_df=0.7)#, stop_words=stopwords.words('english')\n",
        "    X = vectorizer.fit_transform(documents).toarray()\n",
        "    print(X.shape)\n",
        "    return X\n",
        "\n",
        "get_count_vect(df['stop_words_removed_questions'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5000, 1072)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A61URMarm4Gj"
      },
      "source": [
        "Head word Synonyms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFOgrpTlm747",
        "outputId": "3d8550d0-8774-4295-ec2a-132f39c682ca"
      },
      "source": [
        "from nltk.corpus import wordnet \n",
        "nltk.download('wordnet')\n",
        "def get_synonyms(words):\n",
        "    all_synonyms = []\n",
        "    for word in words.split(' '):\n",
        "        synonyms = []\n",
        "\n",
        "        for syn in wordnet.synsets(word):\n",
        "            for l in syn.lemmas():\n",
        "                synonyms.append(l.name())\n",
        "\n",
        "        synonyms = list(set(synonyms))\n",
        "        all_synonyms += synonyms\n",
        "        \n",
        "    return all_synonyms\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHwCddCTnekd",
        "outputId": "38bb814c-1a22-4543-e5c3-e9cc4ac4efa6"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "head_words_synonym_vectorizer = CountVectorizer(tokenizer = get_synonyms,max_features=100,stop_words=stopwords.words('english'))\n",
        "head_words_synonym_vector = head_words_synonym_vectorizer.fit_transform(df['stop_words_removed_questions'].values).toarray()\n",
        "print(head_words_synonym_vector)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'tween\", '1', '1000', '500', 'A', 'AM', 'AN', 'AS', 'Am', 'American_Samoa', 'Artium_Magister', 'As', 'Associate_in_Nursing', 'At', 'Bay_State', 'Be', 'Beaver_State', 'D', 'DO', 'DOE', 'Department_of_Energy', 'Doctor_of_Osteopathy', 'Don', 'Don_River', 'Down', 'Eastern_Samoa', 'Energy', 'Energy_Department', 'Evergreen_State', 'G', 'HA', 'He', 'Hera', 'Here', 'Hoosier_State', 'I', 'IN', 'ISN', 'IT', 'In', 'Indiana', 'International_Relations_and_Security_Network', 'John_L._H._Down', 'K', \"KO'd\", 'Lapp', 'Lapplander', 'M', 'MA', 'MB', 'ME', 'MT', 'Maine', 'Massachusetts', 'Master_of_Arts', 'MiB', 'More', 'No', 'North_Korean_won', 'O', 'OR', 'Old_Colony', 'Oregon', 'Pine_Tree_State', 'Ra', 'Re', 'S', 'Saame', 'Saami', 'Same', 'Sami', 'Shan', 'Sir_Thomas_More', 'South_Korean_won', 'T', 'Tai_Long', 'Thomas_More', 'WA', 'WHO', 'Washington', 'World_Health_Organization', 'Y', 'accept', 'ace', 'acquire', 'act', 'adenine', 'advance', 'afterward', 'afterwards', 'ahead', 'all_over', 'almost', 'alone', 'along', 'also', 'altogether', 'americium', 'amp', 'ampere', 'amplitude_modulation', 'and_so', 'and_then', 'ane', 'angstrom', 'angstrom_unit', 'answer', 'antiophthalmic_factor', 'apiece', 'approximately', 'ar', 'around', 'arrange', 'arse', 'arsenic', 'as_well', 'aside', 'ass', 'assume', 'astatine', 'astir', 'at_a_lower_place', 'at_once', 'at_one_time', 'at_present', 'at_that_place', 'atomic_number_102', 'atomic_number_16', 'atomic_number_2', 'atomic_number_33', 'atomic_number_39', 'atomic_number_4', 'atomic_number_49', 'atomic_number_53', 'atomic_number_75', 'atomic_number_8', 'atomic_number_85', 'atomic_number_95', 'away', 'axerophthol', 'backside', 'barely', 'bash', 'bathroom', 'bear', 'behave', 'behind', 'beingness', 'belt_down', 'beneath', 'bequeath', 'beryllium', 'besides', 'betwixt', 'birth', 'blue', 'bolt_down', 'boost', 'bottom', 'brawl', 'bring_home_the_bacon', 'bum', 'bump_off', 'buns', 'butt', 'buttocks', 'calciferol', 'can_buoy', 'cancelled', 'canful', 'cause', 'chiliad', 'cholecalciferol', 'close_to', 'coif', 'coiffe', 'coiffure', 'come', 'come_out', 'come_out_of_the_closet', 'come_through', 'commode', 'complete', 'completely', 'comprise', 'concluded', 'constitute', 'consume', 'cost', 'crapper', 'cut_down', 'deliver', 'deliver_the_goods', 'deoxyadenosine_monophosphate', 'deoxythymidine_monophosphate', 'depressed', 'derriere', 'devour', 'directly', 'dismiss', 'dispatch', 'dispirited', 'displace', 'doe', 'doh', 'done', 'down_feather', 'down_in_the_mouth', 'down_pat', 'down_the_stairs', 'downcast', 'downhearted', 'downstairs', 'downward', 'downwardly', 'downwards', 'dress', 'drink_down', 'due_south', 'earlier', 'early', 'embody', 'encourage', 'ended', 'entirely', 'entropy', 'equal', 'equally', 'equitable', 'ergocalciferol', 'erst', 'erstwhile', 'every_bit', 'exactly', 'excessively', 'exclusively', 'execute', 'exercise', 'exist', 'existence', 'experience', 'extinct', 'fair', 'fanny', 'far', 'fare', 'farther', 'father', 'feature', 'fine-tune', 'fire', 'five_hundred', 'follow', 'for_each_one', 'forbidden', 'force_out', 'former', 'formerly', 'forth', 'forthwith', 'foster', 'from_each_one', 'fundament', 'gain', 'gain_ground', 'get', 'get_ahead', 'get_along', 'get_into', 'give', 'give_birth', 'give_notice', 'give_the_axe', 'give_the_sack', 'gloomy', 'glucinium', 'go_through', 'good', 'grand', 'grim', 'group_A', 'group_O', 'harbor', 'harbour', 'hardly', 'have_got', 'helium', 'hence', 'higher_up', 'hind_end', 'hindquarters', 'hit', 'hither', 'hold', 'hour_angle', 'identical', 'immediately', 'improving', 'in_a_higher_place', 'in_front', 'in_one_case', 'in_that_location', 'in_that_respect', 'inch', 'indeed', 'indium', 'induce', 'information_technology', 'infra', 'ingest', 'instantly', 'inward', 'inwards', 'iodin', 'iodine', 'john', 'just_about', 'just_now', 'k', 'kayoed', 'keister', 'kill', 'knock_down', 'knocked_out', 'land', 'later', 'later_on', 'lav', 'lavatory', 'leave', 'let', 'like', 'like_a_shot', 'likewise', 'liothyronine', 'live', 'lone', 'lonesome', 'low', 'low-spirited', 'mA', 'make', 'make_headway', 'make_out', 'make_up', 'mama', 'mamma', 'mammy', 'manage', 'mastered', 'mebibyte', 'megabyte', 'merely', 'meter', 'metre', 'metric_ton', 'mho', 'milliampere', 'molar_concentration', 'molarity', 'mom', 'momma', 'mommy', 'more_or_less', 'more_than', 'mum', 'mummy', 'murder', 'nates', 'near', 'nearly', 'nether', 'nigh', 'no_more', 'nobelium', 'non', 'nowadays', \"o'er\", 'oasis', 'on_a_lower_floor', 'on_that_point', 'once_again', 'once_more', 'one', 'one_thousand', 'one_time', 'only_if', 'only_when', 'operating_room', 'operating_theater', 'operating_theatre', 'or_so', 'organism', 'over_again', 'overly', 'oxygen', 'past', 'patch', 'perform', 'personify', 'piece', 'pile', 'polish', 'polish_off', 'pop', 'possess', 'posterior', 'pot', 'potty', 'pour_down', 'practice', 'practise', 'prat', 'preceptor', 'precisely', 'privy', 'prohibited', 'promote', 'proscribed', 'pull_ahead', 'pull_down', 'push_down', 'put_on', 'put_up', 'randomness', 'rattling', 'ray', 'real', 'really', 'rear', 'rear_end', 'receive', 'reciprocal_ohm', 'refine', 'remove', 'represent', 'rhenium', 'rich_person', 'right_away', 'roughly', 'rump', 'sack', 'scarce', 'scarcely', 'seaport', 'seat', 'sec', 'second', 'selfsame', 'send_away', 'serve', 'set', 'shoot_down', 'siemens', 'simply', 'single', 'slay', 'soh', 'sol', 'sole', 'solely', 'solitary', 'sour', 'south', 'southward', 'spell', 'stern', 'stimulate', 'stool', 'straight_off', 'straightaway', 'stunned', 'subsequently', 'succeed', 'suffer', 'suffice', 'sulfur', 'sulphur', 'supra', 'surgery', 'sustain', 'taboo', 'tabu', 'tail', 'tail_end', 'take', 'take_in', 'terminate', 'terminated', 'testament', 'tetraiodothyronine', 'thence', 'therefore', 'thither', 'thou', 'thousand', 'throne', 'through_and_through', 'through_with', 'throw', 'thus', 'thusly', 'thymine', 'thyroxin', 'thyroxine', 'tin', 'tin_can', 'to_a_fault', 'to_a_greater_extent', 'to_a_higher_place', 'to_a_lower_place', 'to_each_one', 'to_the_highest_degree', 'today', 'toilet', 'tonne', 'tooshie', 'toss_off', 'totally', 'triiodothyronine', 'turned', 'tush', 'type_A', 'type_O', 'unity', 'upright', 'upward', 'upwardly', 'upwards', 'ut', 'verboten', 'viosterol', 'virtually', 'vitamin_A', 'vitamin_D', 'volition', 'wealthy_person', 'wear', 'well-nigh', 'whatever', 'whatsoever', 'wherefore', 'whole', 'wholly', 'win', 'wye', 'yard', 'yttrium'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlX3NyL_ElNA"
      },
      "source": [
        "Head Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3_38z2SEnAt"
      },
      "source": [
        "# Head word tokenizer\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "def head_word_tokenizer(text):\n",
        "    head_words = []\n",
        "    for token in nlp(text):\n",
        "        if token.dep_ == \"nsubj\" or token.dep_ == \"nsubjpass\":\n",
        "            head_words.append(token.text)\n",
        "    return head_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMnfBTi7EvIM",
        "outputId": "074affc3-1bcf-4507-9009-c1ed813362ed"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "head_words_vectorizer = CountVectorizer(tokenizer = head_word_tokenizer,max_features=100,stop_words=stopwords.words('english'))\n",
        "head_words_vector = head_words_vectorizer.fit_transform(df[\"stop_words_removed_questions\"].values).toarray()\n",
        "print(head_words_vector)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DkZ3a4y4Onu"
      },
      "source": [
        "Bi-grams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tOMTqZW4QNc",
        "outputId": "5ae6b11d-c495-4277-fa46-9fb342b37681"
      },
      "source": [
        "def bigram(text):\n",
        "    new_words = \"\"\n",
        "    pre_word = None\n",
        "    for word in text.strip().split(' '):\n",
        "        \n",
        "        if pre_word is not None:\n",
        "            new_words += \"{}{} \".format(pre_word, word)\n",
        "        pre_word = word\n",
        "    return new_words[:-1]\n",
        "\n",
        "item = \"What is the ideal time to visit Mauritius in the year as we are planning to get married in there and spend our honeymoon?\";\n",
        "df['bigram_questions'] = [bigram(question) for question in df['stop_words_removed_questions']]\n",
        "\n",
        "print(bigram(item))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Whatis isthe theideal idealtime timeto tovisit visitMauritius Mauritiusin inthe theyear yearas aswe weare areplanning planningto toget getmarried marriedin inthere thereand andspend spendour ourhoneymoon?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouY2ch1v6XKt"
      },
      "source": [
        "Define course class values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mt-2ckW76hM7"
      },
      "source": [
        "def get_class_values(feature_set='coarse'):\n",
        "    le = LabelEncoder()\n",
        "    encoded_classes = le.fit_transform(df[feature_set])\n",
        "    return encoded_classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ru3murev7Y7b"
      },
      "source": [
        "Define evaluation metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJLd_dsI7cU9"
      },
      "source": [
        "def PRC_matrics(y_test, prediction):\n",
        "    # prediction\n",
        "    precision = precision_score(y_test, prediction, labels=np.unique(prediction), average='micro')*100\n",
        "    print('Precision: %.3f' % precision)\n",
        "\n",
        "    # recall\n",
        "    recall = recall_score(y_test, prediction, labels=np.unique(prediction), average='micro')*100\n",
        "    print('Recall: %.3f' % recall)\n",
        "    \n",
        "    # score\n",
        "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "    print('F-Measure: %.3f' % f1_score)\n",
        "    \n",
        "    \n",
        "    acc = accuracy_score(y_test, prediction)*100\n",
        "    print('Accuracy score: %.3f' % acc)\n",
        "    \n",
        "    \n",
        "    cm = confusion_matrix(y_test, prediction)\n",
        "    print(\"\\nConfustion matrix: \\n{}\".format(cm))\n",
        "    \n",
        "    return precision, recall, f1_score, acc, cm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itPRPb8o6rKY"
      },
      "source": [
        "Define SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGxE4Ba36tL2"
      },
      "source": [
        "def train_with_svm(XX, y):\n",
        "    best_prediction = None\n",
        "    best_test = None\n",
        "    best_accuracy = 0\n",
        "    cv = KFold(n_splits=10, random_state=42, shuffle=True)\n",
        "    fold = 0\n",
        "    accuracies = []\n",
        "    for train_index, test_index in cv.split(XX):\n",
        "        fold += 1\n",
        "        X_train, X_test = XX[train_index], XX[test_index]\n",
        "        y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "        SVM = SVC(C=1.0, kernel='linear', degree=4, gamma='auto')\n",
        "        SVM.fit(X_train,y_train)\n",
        "        predictions_SVM1 = SVM.predict(X_test)\n",
        "        acc = accuracy_score(predictions_SVM1, y_test)*100\n",
        "        if best_accuracy < acc:\n",
        "            best_accuracy = acc\n",
        "            best_prediction = predictions_SVM1\n",
        "            best_test = y_test\n",
        "            best_model = SVM\n",
        "        accuracies.append(acc)\n",
        "        print(\"Fold - {} - {} - {:.2f}\".format(fold, \"Accuracy-> \",acc))\n",
        "\n",
        "    print(\"Mean Accuracy {:.2f} \\nStd Accuracy {:.2f}\\n\\n\".format(np.mean(accuracies), np.std(accuracies)))\n",
        "    \n",
        "    print(\"Best accuracy : {}\".format(best_accuracy))\n",
        "    PRC_matrics(best_test, best_prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFSq7ShR74F2"
      },
      "source": [
        "**Question 01: A traditional ML classifier s.a. SVM or Logistic Regression with at least 5  of the features mentioned in the paper**\n",
        "\n",
        "Selected Features\n",
        "\n",
        "*   POS tags\n",
        "*   Named Entities\n",
        "*   Head words\n",
        "*   Head Word Synonyms\n",
        "*   Bi-grams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGaA6yX9-Wkt",
        "outputId": "2043d395-7ad6-4ea0-bd06-da07c9ff7108"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from scipy.sparse import coo_matrix, csr_matrix, hstack\n",
        "\n",
        "\n",
        "coarse = get_class_values('coarse')\n",
        "\n",
        "X_lem = df['lemmatized_questions']\n",
        "tfidf_lem = TfidfVectorizer(max_features=5000)\n",
        "tfidf_lem.fit(X_lem)\n",
        "\n",
        "X_pos = df['pos_tagged_questions']\n",
        "\n",
        "X_ne = df['named_entity_questions']\n",
        "\n",
        "X_bigram = df['bigram_questions']\n",
        "\n",
        "\n",
        "XX = csr_matrix(hstack([tfidf_lem.transform(X_lem) ,get_count_vect(X_pos), get_count_vect(X_ne), get_count_vect(X_bigram),\n",
        "                        head_words_vector,head_words_synonym_vector]))\n",
        "XX.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5000, 22)\n",
            "(5000, 13)\n",
            "(5000, 344)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 5561)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSH7d5xbeGBz"
      },
      "source": [
        "Feature Selection\n",
        "\n",
        "1. Select k best features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pekOB2TReL2B",
        "outputId": "92ba68dc-1636-4152-b613-6929357b0502"
      },
      "source": [
        "\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "\n",
        "X_new = SelectKBest(chi2, k=3500).fit_transform(XX, coarse)\n",
        "X_new.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 3500)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLZqGivvemQH"
      },
      "source": [
        "2. Remove features considering a specified threshold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5zn2hvxep1P",
        "outputId": "af62682d-9fd3-46d1-d0c5-382919d63d41"
      },
      "source": [
        "from sklearn.feature_selection import VarianceThreshold\n",
        "X_new_var = VarianceThreshold(threshold=(0.01)).fit_transform(XX)\n",
        "X_new_var.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 132)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlRc_-JbfC7F"
      },
      "source": [
        "Training using the defined SVM\n",
        "\n",
        "1. Train with coarse classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLcy-jyMfFWB",
        "outputId": "22ebee81-4981-4339-e9af-971ac4cc4dc7"
      },
      "source": [
        "train_with_svm(XX, get_class_values('coarse'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold - 1 - Accuracy->  - 80.20\n",
            "Fold - 2 - Accuracy->  - 78.00\n",
            "Fold - 3 - Accuracy->  - 78.80\n",
            "Fold - 4 - Accuracy->  - 75.80\n",
            "Fold - 5 - Accuracy->  - 76.40\n",
            "Fold - 6 - Accuracy->  - 78.40\n",
            "Fold - 7 - Accuracy->  - 81.00\n",
            "Fold - 8 - Accuracy->  - 77.20\n",
            "Fold - 9 - Accuracy->  - 80.00\n",
            "Fold - 10 - Accuracy->  - 77.60\n",
            "Mean Accuracy 78.34 \n",
            "Std Accuracy 1.60\n",
            "\n",
            "\n",
            "Best accuracy : 81.0\n",
            "Precision: 81.000\n",
            "Recall: 81.162\n",
            "F-Measure: 81.081\n",
            "Accuracy score: 81.000\n",
            "\n",
            "Confustion matrix: \n",
            "[[ 0  0  1  0  0  0  0  0]\n",
            " [ 0 71  0  0  4  0  8  0]\n",
            " [ 0  0 14  2  1  1  6  0]\n",
            " [ 0  1  0 40  3  1  5  0]\n",
            " [ 0  5  1  2 83  6 14  0]\n",
            " [ 0  2  1  0  5 97  4  0]\n",
            " [ 0  5  3  0  7  5 92  0]\n",
            " [ 0  0  0  0  1  0  1  8]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9Vdql3zgGy4"
      },
      "source": [
        "2. Train with fine classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RL-iL6YOgJ7B",
        "outputId": "87c886bd-251d-430a-ce28-47f83a408bfd"
      },
      "source": [
        "train_with_svm(XX, get_class_values('fine'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold - 1 - Accuracy->  - 53.00\n",
            "Fold - 2 - Accuracy->  - 56.60\n",
            "Fold - 3 - Accuracy->  - 50.80\n",
            "Fold - 4 - Accuracy->  - 51.60\n",
            "Fold - 5 - Accuracy->  - 49.40\n",
            "Fold - 6 - Accuracy->  - 49.80\n",
            "Fold - 7 - Accuracy->  - 55.60\n",
            "Fold - 8 - Accuracy->  - 49.80\n",
            "Fold - 9 - Accuracy->  - 53.20\n",
            "Fold - 10 - Accuracy->  - 51.20\n",
            "Mean Accuracy 52.10 \n",
            "Std Accuracy 2.35\n",
            "\n",
            "\n",
            "Best accuracy : 56.599999999999994\n",
            "Precision: 56.600\n",
            "Recall: 58.714\n",
            "F-Measure: 57.637\n",
            "Accuracy score: 56.600\n",
            "\n",
            "Confustion matrix: \n",
            "[[ 0  0  0 ...  0  0  0]\n",
            " [ 0  0  0 ...  0  0  0]\n",
            " [ 0  0  1 ...  0  0  0]\n",
            " ...\n",
            " [ 0  0  0 ... 11  1  0]\n",
            " [ 0  0  0 ...  1  1  0]\n",
            " [ 0  0  0 ...  0  0  1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RHXeYbikDIB"
      },
      "source": [
        "**Question 02: 2. A traditional ML classifier s.a. SVM or Logistic Regression with word embedding features s.a. word2vec or fasttext.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAq7dudgoEOc"
      },
      "source": [
        "Word Embeddings: Using fasttext"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LB795EZVzWNv"
      },
      "source": [
        "def get_embedding(sentence):    \n",
        "    embedding=ft.get_sentence_vector(sentence)\n",
        "    return embedding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXQRx6h1ojXm"
      },
      "source": [
        "X_embedding = np.array([get_embedding(question) for question in df['stop_words_removed_questions'].values])\n",
        "le = LabelEncoder()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93BOToFOt1C5"
      },
      "source": [
        "Train with SVM for coarse classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ma5tXPZ7uHNU",
        "outputId": "5d1f4018-d32f-4400-8b56-038536a40c56"
      },
      "source": [
        "train_with_svm(X_embedding, get_class_values('coarse'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold - 1 - Accuracy->  - 77.80\n",
            "Fold - 2 - Accuracy->  - 78.80\n",
            "Fold - 3 - Accuracy->  - 81.60\n",
            "Fold - 4 - Accuracy->  - 77.80\n",
            "Fold - 5 - Accuracy->  - 78.60\n",
            "Fold - 6 - Accuracy->  - 78.40\n",
            "Fold - 7 - Accuracy->  - 80.20\n",
            "Fold - 8 - Accuracy->  - 76.00\n",
            "Fold - 9 - Accuracy->  - 78.40\n",
            "Fold - 10 - Accuracy->  - 77.80\n",
            "Mean Accuracy 78.54 \n",
            "Std Accuracy 1.43\n",
            "\n",
            "\n",
            "Best accuracy : 81.6\n",
            "Precision: 81.600\n",
            "Recall: 81.600\n",
            "F-Measure: 81.600\n",
            "Accuracy score: 81.600\n",
            "\n",
            "Confustion matrix: \n",
            "[[ 50   0   5   2   0   3   0]\n",
            " [  0  12   0   1   0   4   0]\n",
            " [  1   0  41   2   0   6   0]\n",
            " [  5   0   0  92  10  16   0]\n",
            " [  1   0   0   5 100   6   0]\n",
            " [  3   0   2  11   7  87   0]\n",
            " [  0   0   0   0   0   2  26]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9H5tZBYupBQ"
      },
      "source": [
        "Train with SVM for fine classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikb_3JlauvN-",
        "outputId": "ff8b88ca-76be-4a77-9761-82bd654fab07"
      },
      "source": [
        "train_with_svm(X_embedding, get_class_values('fine'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold - 1 - Accuracy->  - 53.40\n",
            "Fold - 2 - Accuracy->  - 55.80\n",
            "Fold - 3 - Accuracy->  - 57.00\n",
            "Fold - 4 - Accuracy->  - 54.40\n",
            "Fold - 5 - Accuracy->  - 51.60\n",
            "Fold - 6 - Accuracy->  - 54.00\n",
            "Fold - 7 - Accuracy->  - 58.00\n",
            "Fold - 8 - Accuracy->  - 51.00\n",
            "Fold - 9 - Accuracy->  - 55.60\n",
            "Fold - 10 - Accuracy->  - 52.40\n",
            "Mean Accuracy 54.32 \n",
            "Std Accuracy 2.18\n",
            "\n",
            "\n",
            "Best accuracy : 57.99999999999999\n",
            "Precision: 58.000\n",
            "Recall: 65.909\n",
            "F-Measure: 61.702\n",
            "Accuracy score: 58.000\n",
            "\n",
            "Confustion matrix: \n",
            "[[0 0 0 ... 1 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 6 0 0]\n",
            " [0 0 0 ... 1 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yT6HlYQMyTt0"
      },
      "source": [
        "**Question 03: A NN classifier s.a. an LSTM for classification**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqEqEHj0yZzX"
      },
      "source": [
        "# The maximum number of words to be used. (most frequent)\n",
        "MAX_NB_WORDS = 5000\n",
        "# Max number of words in each complaint.\n",
        "MAX_SEQUENCE_LENGTH = 25\n",
        "# This is fixed.\n",
        "EMBEDDING_DIM = 160\n",
        "epochs = 10\n",
        "batch_size = 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38CrEGywIh1J",
        "outputId": "cf3bfcc3-6c6d-40a3-c37c-b91f83bd456d"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, split=' ')\n",
        "tokenizer.fit_on_texts(df['question'].values)\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5445 unique tokens.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZciXFagImxB",
        "outputId": "7ae04648-65c2-4864-d3ae-56166caf847d"
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "X = tokenizer.texts_to_sequences(df['question'].values)\n",
        "print(X[0])\n",
        "features = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "print('Shape of data tensor:', features.shape)\n",
        "\n",
        "\n",
        "def get_class_labels(_type='coarse'):\n",
        "    y = pd.get_dummies(df[_type]).values\n",
        "    print('Shape of label tensor:', y.shape)\n",
        "    return y\n",
        "\n",
        "classes = get_class_labels('coarse')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[254, 63, 1694, 19, 6, 304, 67]\n",
            "Shape of data tensor: (5000, 25)\n",
            "Shape of label tensor: (5000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UY81RiqI5Rr",
        "outputId": "b1dbfbe2-e829-4d9b-dda9-9647bbbee7a6"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding, SpatialDropout1D, LSTM, Dense\n",
        "from tensorflow.keras import Sequential\n",
        "\n",
        "#Define the lstm model\n",
        "def get_lstm_model(X, y, verbose=0):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n",
        "    #0.2 dropout rate is used\n",
        "    model.add(SpatialDropout1D(0.2))\n",
        "    model.add(LSTM(196, dropout=0.2, recurrent_dropout=0.2))\n",
        "    #softmax is used as the activation function\n",
        "    model.add(Dense(y.shape[1], activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    if verbose == 1:\n",
        "        print(model.summary())\n",
        "    return model\n",
        "\n",
        "get_lstm_model(features, get_class_labels('fine'), 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of label tensor: (5000, 79)\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_6 (Embedding)      (None, 25, 160)           800000    \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_6 (Spatial (None, 25, 160)           0         \n",
            "_________________________________________________________________\n",
            "lstm_6 (LSTM)                (None, 196)               279888    \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 79)                15563     \n",
            "=================================================================\n",
            "Total params: 1,095,451\n",
            "Trainable params: 1,095,451\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.sequential.Sequential at 0x7f3c84a1ad90>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "po7IXATlJEsg",
        "outputId": "a6b62c33-cd7a-48e3-f781-a0b30a60bc2f"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Split train and test as train: 80% and test : 20%\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(features,classes, test_size = 0.20, random_state = 42)\n",
        "print(X_train.shape,Y_train.shape)\n",
        "print(X_test.shape,Y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4000, 25) (4000, 10)\n",
            "(1000, 25) (1000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXd1vw48JK5I"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "epochs = 10\n",
        "batch_size = 64\n",
        "\n",
        "def train_LSTM(X, y):\n",
        "    best_prediction = None\n",
        "    best_test = None\n",
        "    best_accuracy = 0\n",
        "    \n",
        "    #K fold cross validation is used with 10 splits\n",
        "    cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
        "    fold = 0\n",
        "    accuracies = []\n",
        "    for train_index, test_index in cv.split(X):\n",
        "        fold += 1\n",
        "        print(\"FOLD {}\".format(fold))\n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "        model = get_lstm_model(X, y, 0)\n",
        "\n",
        "        hist = model.fit(X_train, y_train, verbose=0, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])\n",
        "        predictions = model.predict(X_test)\n",
        "        for item in hist.history.items():\n",
        "            mean_val = np.mean(item[1])\n",
        "            if item[0] == 'accuracy':\n",
        "                acc = mean_val\n",
        "            print(\"Mean {} : {}\".format(item[0], mean_val))\n",
        "        \n",
        "        \n",
        "        print(\"\\n\")\n",
        "        if best_accuracy < acc:\n",
        "            best_accuracy = acc\n",
        "            best_prediction = predictions\n",
        "            best_test = y_test\n",
        "            \n",
        "    fine_pred = [np.argmax(p) for p in best_prediction]\n",
        "    fine_gt = [np.argmax(p) for p in best_test]\n",
        "    PRC_matrics(fine_pred, fine_gt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9U8QbWJVJNsg",
        "outputId": "053ca3a6-f50b-488d-8544-63e81935efc1"
      },
      "source": [
        "train_LSTM(features, get_class_labels('coarse'))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of label tensor: (5000, 10)\n",
            "FOLD 1\n",
            "Mean loss : 0.5125426459126174\n",
            "Mean accuracy : 0.8130555674433708\n",
            "Mean val_loss : 1.218598186969757\n",
            "Mean val_accuracy : 0.5986111266538501\n",
            "\n",
            "\n",
            "FOLD 2\n",
            "Mean loss : 0.4642193594740497\n",
            "Mean accuracy : 0.8363237414095137\n",
            "Mean val_loss : 1.096541358364953\n",
            "Mean val_accuracy : 0.6486419720782174\n",
            "\n",
            "\n",
            "FOLD 3\n",
            "Mean loss : 0.5228382371779945\n",
            "Mean accuracy : 0.8091357946395874\n",
            "Mean val_loss : 1.2897752655877008\n",
            "Mean val_accuracy : 0.6071604995263947\n",
            "\n",
            "\n",
            "FOLD 4\n",
            "Mean loss : 0.7397257698078951\n",
            "Mean accuracy : 0.7301646073659261\n",
            "Mean val_loss : 1.1563325822353363\n",
            "Mean val_accuracy : 0.578518512348334\n",
            "\n",
            "\n",
            "FOLD 5\n",
            "Mean loss : 0.6294968032411167\n",
            "Mean accuracy : 0.7709700231041227\n",
            "Mean val_loss : 1.2383652925491333\n",
            "Mean val_accuracy : 0.5698412539703506\n",
            "\n",
            "\n",
            "FOLD 6\n",
            "Mean loss : 0.5167178735136986\n",
            "Mean accuracy : 0.8127297643158171\n",
            "Mean val_loss : 1.1949146389961243\n",
            "Mean val_accuracy : 0.6782716049088372\n",
            "\n",
            "\n",
            "FOLD 7\n",
            "Mean loss : 0.5866294189223221\n",
            "Mean accuracy : 0.7880070507526398\n",
            "Mean val_loss : 1.249675146171025\n",
            "Mean val_accuracy : 0.5793650852782386\n",
            "\n",
            "\n",
            "FOLD 8\n",
            "Mean loss : 0.5834108857171876\n",
            "Mean accuracy : 0.7929453296320779\n",
            "Mean val_loss : 1.1864164301327296\n",
            "Mean val_accuracy : 0.6053968306098666\n",
            "\n",
            "\n",
            "FOLD 9\n",
            "Mean loss : 0.6752497317890326\n",
            "Mean accuracy : 0.7556790014108022\n",
            "Mean val_loss : 1.2041593492031097\n",
            "Mean val_accuracy : 0.5829629662136236\n",
            "\n",
            "\n",
            "FOLD 10\n",
            "Mean loss : 0.680522732436657\n",
            "Mean accuracy : 0.7604115307331085\n",
            "Mean val_loss : 1.2511661847432454\n",
            "Mean val_accuracy : 0.5662962968150774\n",
            "\n",
            "\n",
            "Precision: 80.400\n",
            "Recall: 80.400\n",
            "F-Measure: 80.400\n",
            "Accuracy score: 80.400\n",
            "\n",
            "Confustion matrix: \n",
            "[[ 72   0   2   2   1   5   0   1]\n",
            " [  1  15   0   0   0   0   0   0]\n",
            " [  1   1  33   2   0   1   0   0]\n",
            " [  4   0   1 100   9  10   0   1]\n",
            " [  0   0   0  10  75   6   0   2]\n",
            " [  4   8   3   9   9  88   1   2]\n",
            " [  0   0   0   0   0   0   0   0]\n",
            " [  0   1   0   1   0   0   0  19]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MD2uRVRCJRlE",
        "outputId": "e6554ca0-4e6c-4767-fb55-b481655b74fd"
      },
      "source": [
        "train_LSTM(features, get_class_labels('fine'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of label tensor: (5000, 79)\n",
            "FOLD 1\n",
            "Mean loss : 1.7968821823596954\n",
            "Mean accuracy : 0.5749135829508305\n",
            "Mean val_loss : 2.7323614835739134\n",
            "Mean val_accuracy : 0.32822222271934154\n",
            "\n",
            "\n",
            "FOLD 2\n",
            "Mean loss : 1.691644588112831\n",
            "Mean accuracy : 0.6017530843615532\n",
            "Mean val_loss : 2.672770953178406\n",
            "Mean val_accuracy : 0.40888888835906984\n",
            "\n",
            "\n",
            "FOLD 3\n",
            "Mean loss : 1.8120527505874633\n",
            "Mean accuracy : 0.5691851913928986\n",
            "Mean val_loss : 2.6035063743591307\n",
            "Mean val_accuracy : 0.37866666400805116\n",
            "\n",
            "\n",
            "FOLD 4\n",
            "Mean loss : 1.7629392340779304\n",
            "Mean accuracy : 0.5853086426854134\n",
            "Mean val_loss : 2.7090800523757936\n",
            "Mean val_accuracy : 0.3919999999925494\n",
            "\n",
            "\n",
            "FOLD 5\n",
            "Mean loss : 1.7554625779390336\n",
            "Mean accuracy : 0.5830617241561413\n",
            "Mean val_loss : 2.6617604732513427\n",
            "Mean val_accuracy : 0.37244444992393255\n",
            "\n",
            "\n",
            "FOLD 6\n",
            "Mean loss : 1.84823559390174\n",
            "Mean accuracy : 0.5613991792003313\n",
            "Mean val_loss : 2.6430780622694225\n",
            "Mean val_accuracy : 0.3713580262329843\n",
            "\n",
            "\n",
            "FOLD 7\n",
            "Mean loss : 2.0450053587555885\n",
            "Mean accuracy : 0.5133950626477599\n",
            "Mean val_loss : 2.6392596065998077\n",
            "Mean val_accuracy : 0.3711111058946699\n",
            "\n",
            "\n",
            "FOLD 8\n",
            "Mean loss : 2.0177813503477307\n",
            "Mean accuracy : 0.5210973934994804\n",
            "Mean val_loss : 2.8281022707621255\n",
            "Mean val_accuracy : 0.3612345651619964\n",
            "\n",
            "\n",
            "FOLD 9\n",
            "Mean loss : 1.7460508674383164\n",
            "Mean accuracy : 0.5844691380858421\n",
            "Mean val_loss : 2.7159308910369875\n",
            "Mean val_accuracy : 0.3713333369232714\n",
            "\n",
            "\n",
            "FOLD 10\n",
            "Mean loss : 1.6499710068106652\n",
            "Mean accuracy : 0.6120740748941899\n",
            "Mean val_loss : 2.5437347888946533\n",
            "Mean val_accuracy : 0.3988888841122389\n",
            "\n",
            "\n",
            "Precision: 61.200\n",
            "Recall: 61.569\n",
            "F-Measure: 61.384\n",
            "Accuracy score: 61.200\n",
            "\n",
            "Confustion matrix: \n",
            "[[ 2  0  0 ...  0  0  0]\n",
            " [ 0  4  0 ...  0  0  0]\n",
            " [ 0  0 31 ...  0  0  0]\n",
            " ...\n",
            " [ 0  0  0 ...  8  1  1]\n",
            " [ 0  0  0 ...  1  0  0]\n",
            " [ 0  0  0 ...  1  0  1]]\n"
          ]
        }
      ]
    }
  ]
}