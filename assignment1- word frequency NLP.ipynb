{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOUqqvVR6ji9hYyg3jnwPKx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UthpalaPitawela/Data_Science_Implementations/blob/main/assignment1-%20word%20frequency%20NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58Aecm6q_uob"
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import webtext\n",
        "from nltk.probability import FreqDist"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efsf8OM9_qV_"
      },
      "source": [
        "For Sinhala "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXQcu5NZ_vCj",
        "outputId": "29ba0764-3f40-4313-fca4-a1df4d4ba636"
      },
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "frequency = {}\n",
        "#Open the sample text file in read mode.\n",
        "document_text = open('/content/sinhala.txt', 'r')\n",
        "#convert the string of the document and assign it to text_string variable.\n",
        "text = document_text.read().split()\n",
        "for word in text:\n",
        "     count = frequency.get(word,0)\n",
        "     frequency[word] = count + 1\n",
        "#frequency_list = frequency.keys()\n",
        "#for words in frequency_list:\n",
        "#print(words, frequency[words])\n",
        "\n",
        "\n",
        "new = pd.DataFrame.from_dict(frequency, orient ='index')\n",
        "print(new)\n",
        "\n",
        "new.to_csv(\"/content/sample_data/sinhala_output.csv\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                0\n",
            "අමාත්‍යාංශ     72\n",
            "කටයුතු       1224\n",
            "මෙහෙයවීමට       2\n",
            "වාසුදේව        10\n",
            "නානායක්කාර     16\n",
            "...           ...\n",
            "යෙෞවන           1\n",
            "කාර්යාලයේ      1\n",
            "පරිසරයට         1\n",
            "වේලා            1\n",
            "රාජ්‍යයේයේ     1\n",
            "\n",
            "[19249 rows x 1 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCgcdW1nCbgL"
      },
      "source": [
        "For Tamil"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jY89QVtlCdvp",
        "outputId": "204ee2a0-bc3a-42c1-c753-7cd226172014"
      },
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "frequency = {}\n",
        "#Open the sample text file in read mode.\n",
        "document_text = open('/content/tamil.txt', 'r')\n",
        "#convert the string of the document and assign it to text_string variable.\n",
        "text = document_text.read().split()\n",
        "for word in text:\n",
        "     count = frequency.get(word,0)\n",
        "     frequency[word] = count + 1\n",
        "#frequency_list = frequency.keys()\n",
        "#for words in frequency_list:\n",
        "#print(words, frequency[words])\n",
        "\n",
        "\n",
        "new = pd.DataFrame.from_dict(frequency, orient ='index')\n",
        "print(new)\n",
        "\n",
        "new.to_csv(\"/content/sample_data/tamil_output.csv\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                    0\n",
            "அமைச்சின்         332\n",
            "பணிகளை             46\n",
            "முன்னெடுப்பதற்கு    3\n",
            "கௌர                 2\n",
            "அமைச்சர்          150\n",
            "...               ...\n",
            "வடிவமைக்கவென        1\n",
            "பதிப்புக்           1\n",
            "பதின்நான்காவது      1\n",
            "வ்வாறு              1\n",
            "இ்ச்                1\n",
            "\n",
            "[36385 rows x 1 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFHyuwK4_Igz"
      },
      "source": [
        "# New Section"
      ]
    }
  ]
}